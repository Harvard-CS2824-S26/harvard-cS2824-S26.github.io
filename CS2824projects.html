<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<head>
  <script async src=""></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-46766886-4');
  </script>


<script type="text/javascript">
  function visibility_on(id) {
       var e = document.getElementById(id+"_text");
       if(e.style.display == 'none')
           e.style.display = 'block';
       var e = document.getElementById(id+"_img");
       if(e.style.display == 'none')
           e.style.display = 'block';
  }
  function visibility_off(id) {
       var e = document.getElementById(id+"_text");
       if(e.style.display == 'block')
           e.style.display = 'none';
       var e = document.getElementById(id+"_img");
       if(e.style.display == 'block')
           e.style.display = 'none';
  }
  function toggle_visibility(id) {
      var e = document.getElementById(id+"_text");
      if(e.style.display == 'inline')
         e.style.display = 'block';
      else
         e.style.display = 'inline';
      var e = document.getElementById(id+"_img");
      if(e.style.display == 'inline')
         e.style.display = 'block';
      else
         e.style.display = 'inline';
  }
  function toggle_vis(id) {
      var e = document.getElementById(id);
      if (e.style.display == 'none')
          e.style.display = 'inline';
      else
          e.style.display = 'none';
  }
</script>


  <meta name=viewport content="width=800">
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
    /* Color scheme stolen from Sergey Karayev */
    
    a {
      color: #1772d0;
      text-decoration: none;
    }
    
    a:focus,
    a:hover {
      color: #f09228;
      text-decoration: none;
    }
    
    body,
    td,
    th,
    tr,
    p,
    a {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px
    }
    
    strong {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px;
    }
    
    heading {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 22px;
    }
    
    papertitle {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px;
      font-weight: 700
    }
    
    name {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 32px;
    }
    
    .one {
      width: 160px;
      height: 160px;
      position: relative;
    }
    
    .two {
      width: 160px;
      height: 160px;
      position: absolute;
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }
    
    .fade {
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }
    
    span.highlight {
      background-color: #ffffd0;
    }
  </style>
  <link rel="icon" type="image/png" href="images/seal_icon.png">
  <title>CS 6789 Foundations of RL</title>
  <meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
</head>


<body>
  <table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
      <td>
        

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <p align="center">
                <name>Important Dates</name>
              </p>
              <p>
                <br><strong>Midterm report due: </strong> TBD</br>
                <br><strong>Project Presentations: </strong> TBD</br>
                <br><strong> Final report due: </strong> TBD </br>
              </br>
              </p>
            </td>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <p align="center">
                <name>Gradings</name>
              </p>
              <p>
                <br><strong>Midterm report: </strong> 5%</br>
                <br><strong>Project Presentations: </strong> 10%</br>
                <br><strong> Final report due: </strong> 15% </br>
              </br>
              </p>
            </td>
          </tr>
        </table>


        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <p align="center">
                <name>Reports and Presentations</name>
              </p>
              <p>
                <strong>Presentations</strong>: Details forthcoming.
              </p>
              <p> <strong>Report Format</strong>: we use <a href="https://neurips.cc/Conferences/2020/CallForPapers">NeurIPS format</a>. You must use the NeurIPS LaTex format. 
              <p><strong>Midterm Report</strong>: Your report should be 2 pages maximum (not including references). Your midterm report should include title, team members, abstract, related works, problem formulation and goals. 
              </p>
              <p><strong>Final Report</strong>: Your report should be 9 pages maximum (not including references). Your final report will be evaluated by the following criteria:
                <ul>
                <li> Merit: Do you have sound reasoning for the approach? Is the question well motivated and are you taking a justifiably simple approach or, if you are choosing a more complicated method, do you have sound reasoning for doing this?</li>
                <li>Technical depth: How technically challenging was what you did? Did you use a package or write your own code? It is fine if you use a package, though this means other aspects of your project must be more ambitious.</li>
                <li>Presentation: How well did you explain what you did, your results, and interpret the outcomes? Did you use good graphs and visualizations? How clear was the writing? Did you justify your approach?</li>
                </ul>
              </p>
            </td>
          </tr>
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="67%" valign="middle">
              <p align="center">
                <name>Project Ideas</name>
                
              </p>

              <p> We provide a few project ideas below. Studying existing RL theory papers and reproducing proofs is also a good option for the course project. Experiments
                for verifying  conclusions and testing conjectures are also welcome.
              </p>
              
              <br> <strong> Refined analysis in Tabular MDPs: </strong> Conduct a survey on a family of tabular MDP papers with tight regret bounds, e.g., <a href="https://arxiv.org/abs/1703.05449"> Azar et.al </a>, 
              <a
              href="http://papers.nips.cc/paper/7735-is-q-learning-provably-efficient">Jin
	      et.al</a>, 
	      <a href="https://arxiv.org/abs/2005.00527">Wang et.al</a>
	      </br>

              <br> <strong> Comparison between variants of linear MDP models: </strong> Conduct a survey on papers with some kind of linear structures, e.g., <a href="https://arxiv.org/abs/1905.10389"> Yang and Wang </a>, 
              <a href="http://proceedings.mlr.press/v125/jin20a/jin20a.pdf">Jin et.al</a> </br>

              <br> <strong> Thompson Sampling in RL: </strong> Survey Thompson sampling techniques used in RL. <a href="https://djrusso.github.io/docs/TS_Tutorial.pdf">This</a> is a good starting point. 
              </br>

              <br> <strong> Gittins Index: </strong> Understand and survey the
              Gittins index method. This is a framework for Bayes
              optimal learning for multi-armed
              bandits. Think about open questions and why extensions
              are difficult. <a href="https://www.mit.edu/~jnt/Papers/J048-94-jnt-gittins.pdf">This</a> is a good starting point. 
              </br>
	      
              <br> <strong> RL with Constraints: </strong>  RL with convex and knapsack constraints is studied <a href="https://arxiv.org/pdf/2006.05051.pdf">here</a> for tabular settings. 
               Can you extend it to non-tabular setting such as linear MDPs? </br>

               <br> <strong> RL with Adversarial Corruption: </strong>  Exploration in RL with corruption is studied <a href="https://arxiv.org/abs/1911.08689">here</a>. 
               Can you think about different attack models and study attack/defense in other RL frameworks such as policy gradient or batch RL? </br>

               <br> <strong> Policy Gradient: </strong> Starting from <a href="https://arxiv.org/abs/1908.00261"> the analysis of PG/NPG</a>, can you think about how to do 
               data-reuse in policy optimization to potentially improve its sample complexity?  </br>

               <br> <strong> Policy Gradient with Exploration: </strong> Starting from <a href="https://arxiv.org/abs/2007.08459">PC-PG</a>, can you think about ways to improve
               its sample complexity?   </br>

               <br> <strong> Policy Gradient: </strong> Starting from <a href="https://arxiv.org/abs/1912.05830"> this paper</a>, can you think about how to extend the algorithm here 
               to other linear MDP models? </br>

<br> <strong> Reward Free Exploration: </strong>
Conduct a survey on a MDP methods, which do not use a
reward signal. See <a
href="https://arxiv.org/abs/1812.02690">Max-Ent
exploration</a> as a starting point.</br>

               <br> <strong> Imitation Learning from many experts: </strong>  <a href="https://arxiv.org/pdf/2007.00795.pdf"> This paper </a> shows learning from 
               multiple  experts in the interactive learning setting. Can we do learning from multiple experts in non-interactive settings? </br>

<br> <strong> Online MDPs with expert advice.</strong>
Sometimes RL can be done in adversarial contexts. Conduct a survey of
online MDP methods (in adversarial settings). See <a
href="https://homes.cs.washington.edu/~sham/papers/rl/onlineMDP.pdf">Online
MDPs</a> as a starting point. Also, comment on the connections to the
NPG analysis.</br>

               <br> <strong> Safe Control: </strong>  Control barrier function has been used for learning safe policies
                (e.g., <a href="https://arxiv.org/abs/1912.10099">this paper</a>). Can we provide learning guarantees (e.g., regret analysis) for safe RL? </br>

                <br> <strong> Meta Learning in RL or Imitation Learning: </strong> Can you formulate the setting of Meta-learning in RL or Imitation learning? Multitask RL has been 
                previously studied in tabular setting (e.g., <a href="https://www.cs.cmu.edu/~ebrun/BrunskillUAI13Sample.pdf">this paper</a>) </br>

                <br> <strong> Thompson Sampling for Kernelized Nonlinear Regulator: </strong> Can you think about Thompson sampling algorithms for 
                  <a href="https://arxiv.org/pdf/2006.12466.pdf">KNRs</a>?</br>

                  <br> <strong> Hierarchical RL: </strong> when the action space is complex, and/or the planning horizon is long, it is often considered helpful to impose a hierarchy on the action space. This has been formalized in theory using frameworks such as 
                <a href="https://people.cs.umass.edu/~barto/courses/cs687/Sutton-Precup-Singh-AIJ99.pdf">options</a>. There is some theory on the benefits of doing 
                this <a href="https://arxiv.org/pdf/1703.08667.pdf">here</a>. For a reading project, survey these or other papers which focus on techniques for hierarchical RL.
                For a novel project, think about how to analyze learning with options and how to formalize Hierarchical rl and its theoretical benefits. </br>

              <br> <strong> Square Root T Regret in Large Scale MDPs</strong>. Can you modify and turn the <a href="https://arxiv.org/abs/1610.09512">Bellman Rank</a> and <a href="https://arxiv.org/abs/1811.08540">Witness rank</a> papers' algorithms and analysis to a square root T regret bound?
            </br>


            </td>
          </tr>
        </table>

       


            </td>
          </tr>
        </table>


        


     


        
        </td>
    </tr>
  </table>
</body>

</html>
