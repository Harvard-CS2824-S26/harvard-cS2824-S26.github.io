\chapter{Linear Bellman Completeness}
\label{chap:Bellman_complete}
%\chapter{Linear Bellman Completion under a Generative Model}

%\emph{To be added...}
%\iffalse

Up to now we have focussed on ``tabular'' MDPs, where the sample
complexity (and the computational complexity) scaled polynomially in
the size of the state and action spaces. Ultimately, we seek to obtain
methods which are applicable to cases where number of states and
actions is large (or, possibly, countably or uncountably infinite).
%This is essentially a question of generalization.

In this chapter, we will consider one of the simplest conditions,
where such a result is possible. In particular, we
will consider a setting where we have a set of features which satisfy
the \emph{linear Bellman completion} condition, and we show that, with
access to a generative model, there is a simple algorithm that learns
a near optimal policy with polynomial sample complexity in the
dimension of these features.

The linear Bellman completeness concept and first analysis was due to
~\cite{munos2005error}. This chapter studies this concept in
the setting of finite horizon MDPs, where we have access to a generative model.



\section{The Linear Bellman Completeness Condition}

We will work with given a feature mapping $\phi:\Scal\times\Acal\mapsto
\mathbb{R}^{d}$, where we assume the following property is true: given any linear
function $f(s,a) := \theta^{\top} \phi(s,a)$, we have that the Bellman
operator applied to $f(s,a)$ also returns a linear function with
respect to $\phi$. Precisely, we have: 
\begin{definition}[Linear Bellman Completeness] 
  \iffalse The reward function is linear in feature $\phi$, i.e.,
  $r(s,a) = (w^\star)^{\top} \phi(s,a)$ with
  $r(s,a) \in [0,1],\forall s,a\in\Scal\times\Acal$.  \sk{we do not
    need the reward condition.}  \wen{i think we do? since
    $Q^\star_{H-1} = r$ which means to be linear?}  \fi We say the
  features $\phi$ satisfy the \emph{linear Bellman completeness}
  property if for all $\theta \in \mathbb{R}^d$ and
  $(s,a,h) \in \Scal\times\Acal\times[H]$, there exists
  $ w\in\mathbb{R}^d$ such that:
%linear function $f(s,a) :=
%\theta^{\top} \phi(s,a)$ for some $\theta \in \mathbb{R}^d$, we have: 
\begin{align*}
%\forall h\in [H]:  \exists w\in\mathbb{R}^d, \text{s.t., }  
w^{\top} \phi(s,a) = r(s,a) + \mathbb{E}_{s'\sim P_h(s,a)} \max_{a'} \theta^{\top} \phi(s',a').
\end{align*} 
As $w$ depends on $\theta$, we use the notation $\Tcal_h: \mathbb{R}^d\mapsto \mathbb{R}^d$ to
represent such a $w$, i.e., $w := \Tcal_h( \theta )$ in the above equation.  \label{def:linear_bellman_complete}
\end{definition} 
Note that the above implies that $r(s,a) $ is in the span of
$\phi$ (to see this, take $\theta=0$). Furthermore, it also implies that 
%Note that the above model implies that 
$Q^\star_h(s,a)$ is linear in
$\phi$, i.e., there exists $\theta_h^\star$ such that
$Q^\star_h(s,a) = (\theta_h^\star)^{\top} \phi(s,a)$. We can easily
see that tabular MDP is captured by the linear Bellman completeness
with $\phi(s,a) \in \mathbb{R}^{|\Scal||\Acal|}$ being a one-hot
encoding vector with zeros everywhere except one at the entry
corresponding to state-action $(s,a)$. 
%Note that here we do not place
%any restriction on the norm of the feature $\phi$. 
In Chapters~\ref{chap:linear_MDPs} and ~\ref{chap:Bellman_rank}, we
will provide precise examples of models which satisfy the linear
Bellman completeness condition. 

We focus on the generative model setting, i.e., where we can input any
$(s,a)$ pair to obtain a next state sample $s' \sim P(s,a)$ and reward
$r(s,a)$. Our goal here is to design an algorithm that finds a policy
$\widehat\pi$ such that $V^{\widehat\pi} \geq V^\star - \epsilon$,
with number of samples scaling polynomially with respect to all
relevant parameters $d, H, 1/\epsilon$.

%Since we assume reward is always bounded $r(s,a) \in [0,1]$, we have $Q^\star_h(s,a) := (\theta_h^\star)^{\top} \phi(s,a) \in [0, H]$, for all $h \in [H]$.

\section{The LSVI Algorithm}

We first present the least square value iteration (LSVI) algorithm (Alg.~\ref{alg:lsvi}) here. The algorithm takes $H$ many datasets $\Dcal_0,\dots, \Dcal_{H-1}$ as inputs, where each $\Dcal_h = \{ s,a,r, s' \}$. 

\begin{algorithm}[t]
\begin{algorithmic}[1]
%\State Compute the D-optimal design $\rho$ (Eq.~\ref{eq:d_design})
\State \textbf{Input}: $\Dcal_0,\dots, \Dcal_{H-1}$ %Set $V_{H}(s) = 0$ for all $s\in\Scal$
\State Set $V_{H}(s) = 0$ for all $s\in \Scal$
\For{$h = H-1 \to 0$}
    %\State  $\forall (s,a) \in \text{support}(\rho)$, i.i.d sample $\lceil N\rho(s,a) \rceil$ many next states $\Dcal_{s,a} : = \{{s'}^i\}_{i=1}^{\lceil \rho(s,a)N \rceil}$ with ${s'}^i \sim P_h(\cdot | s,a)$
    \State Solve least squares 
    \begin{align}
    \theta_{h} = \arg\min_{\theta }  \sum_{s,a,r, s'\in \Dcal_{h}} \left( \theta^{\top} \phi(s,a)  - r - V_{h+1}({s'}) \right)^2 \label{eq:ls_bc}
    \end{align}  \label{line:lsvi_regression}
    \State Set $V_{h}(s) = \max_{a\in\Acal} \theta_h^{\top} \phi(s,a), \forall s$
\EndFor
\State \textbf{Return:} $\{\widehat\pi_h(s)\}_{h=0}^{H-1}$ where $\widehat{\pi}_h(s) := \arg\max_{a} \theta_h^{\top} \phi(s,a), \forall s, h$.
\end{algorithmic}
\caption{Least Squares Value Iteration}
\label{alg:lsvi}
\end{algorithm}
%\wen{tuples, make math equation}

For each time step, LSVI  estimate $Q^\star_h(s,a)$ via $\theta_h^{\top} \phi(s,a)$ with $\theta_h$ computed from a least square problem. 

To make sure the algorithm succeeds in terms of finding a near optimal policy, we need to design the datasets $\Dcal_0,\dots, \Dcal_{H-1}$. Intuitively, we may want to make sure that in each $\Dcal_h$, we have $\sum_{s,a\in\Dcal_h} \phi(s,a) \phi(s,a)^{\top}$ being full rank, so that least square has closed-form solution, and $\theta_h$ has a good generalization bound.  In the next section, we will leverage the generative model setting and the D-optimal design to construct such datasets.  

%The algorithm consists of two procedures: (1) designing a state-action sampling distribution $\rho\in\Delta(\Scal\times\Acal)$, and (2) running \emph{least square value iteration} using samples $\{s,a,r,s'\}$ with $s,a\sim \rho, r = r(s,a)$ and $s'\sim P_h(\cdot | s,a)$. 


\section{LSVI with D-Optimal Design}

In this section, we start by introducing the D-optimal design and its properties.  We then use the D-optimal design to construct a dataset and give a generalization bound for the solution to the least squares problem on the constructed dataset. Finally, we present the sample complexity bound for LSVI and its analysis.  

We will use the notation $\|x\|_M^2 = x^\top M x$ for a matrix $M$ and
vector $x$ of appropriate dimensions.

\subsection{D-Optimal Design}

We now specify a sampling distribution which, roughly speaking, ensures
good coverage (in a spectral sense) over our feature set.

\begin{theorem} \label{them:design_rho} Suppose $\mathcal{X}\subset
  \R^d$ is a compact set (and full dimensional). There exists a distribution  $\rho$  on
  $\mathcal{X}$ such that:
\begin{itemize}
\item $\rho$ is supported on at most $d(d+1)/ 2$ points (all of which
  are in $\mathcal{X}$).
\item Define
\[
\Sigma = \mathbb{E}_{x\sim \rho} [xx^{\top}.]
\] 
We have that for all $x\in \mathcal{X}$, 
\[
\left\| x \right\|^2_{\Sigma^{-1}}  \leq d.
\]
\end{itemize}
The distribution $\rho$ is referred to as the D-optimal design.
\end{theorem}
With these two properties, one can show that for any $x\in\Xcal$, it can be written as a linear combination of the points on the support of $\rho$, i.e., $x = \sum_{x_i\in\text{support}(\rho)} \alpha_{i}  \rho(x_i) x_i $, where $\|\alpha\|^2_2 \leq d$. %This implies that without loss of generality, we can express any $x\in\Xcal$ via its coordinates $\alpha$ 

The following specifies an explicit construction: $\rho$ is the
following maximizer:
\begin{align}
\rho \in \argmax_{\nu \in \Delta(\mathcal{X})} \ln\det\left( \mathbb{E}_{x\sim
  \nu} x x^{\top}  \right).
\label{eq:d_design}
\end{align} 
(and there exists an optimizer which is supported on at most $d(d+1)/ 2$ points).
The design
$\rho$ has a geometric interpretation: the centered ellipsoid
$\mathcal{E} = \{ v: \|v\|^2_{\Sigma^{-1}} \leq d\}$ is the unique
minimum volume centered ellipsoid containing $\mathcal{X}$
We do not provide the proof here (See Section~\ref{chapterBC_bib}).
%\sk{Let's only provide references at the start of chapters and in the
  %bib section of consistency. this makes it read more like a book
%  rather than a paper. I moved the refs to the bib section.}

In our setting, we will utilize the D-optimal design on the set $\Phi := \{ \phi(s,a): s,a\in\Scal\times\Acal \}$. 

\paragraph{Change of basis interpretation with D-optimal design.} Consider the
coordinate transformation:
\[
\widetilde x := \Sigma^{-1/2} x.
\]
Here we have that:
\[
\widetilde\Sigma := \mathbb{E}_{x\sim \rho} [\widetilde x \widetilde x^{\top}] = I.
\]
Furthermore, we still have that $\left\| \widetilde x
\right\|^2_{\widetilde{\Sigma}^{-1}}  \leq d$.
In this sense, we can interpret the D-optimal design as providing a
well-conditioned sampling distribution for the set $\mathcal{X}$.

\iffalse
We design the sampling distribution $\rho$ using John's ellipsoid. Denote $\Phi := \{ \phi(s,a): s,a\in\Scal\times\Acal \}$. Assume $\Phi$ is compact and without loss of generality, we also assume $\text{span}(\Phi) = \mathbb{R}^d$. Denote $\rho$ as the maximizer of the following equation:
\begin{align}
\rho = \argmax_{\nu \in \Delta(\Scal\times\Acal)} \ln\det\left( \mathbb{E}_{s,a\sim \nu} \phi(s,a) \phi(s,a)^{\top}  \right).
\label{eq:d_design}
\end{align} This $\rho$ is often called D-optimal design. D-optimal design has the following property:

\begin{lemma} \label{lemma:design_rho}For the D-optimal design $\rho$ shown in Eq.~\ref{eq:d_design}, we have (1) $|\text{support}(\rho)| \leq d(d+1)/ 2$, (2) denote $\Sigma = \mathbb{E}_{s,a\sim \rho} \phi(s,a)\phi(s,a)^{\top}$, we have $\max_{s,a\in\Scal\times\Acal} \left\| \phi(s,a) \right\|^2_{\Sigma^{-1}}  \leq d$.
\end{lemma}

Also note that  since $\text{span}(\Phi) = \mathbb{R}^d$, we must have $\text{rank}(\Sigma) = d$. 


Intuitively, $\rho$ is a diverse distribution over $\Scal\times\Acal$
such that every possible $\phi(s,a)$ is covered by $\rho$ in the sense
that $\phi(s,a)^{\top} \Sigma^{-1} \phi(s,a) \leq d$. The design
$\rho$ has a geometric interpretation: the centered ellipsoid
$\mathcal{E} = \{ x: \|x\|^2_{\Sigma^{-1}} \leq d\}$ is the unique
minimum volume centered ellipsoid containing $\Phi$ (i.e., $\Phi
\subset \mathcal{E}$).  We do not provide the proof here (See Section~\ref{chapterBC_bib}).
\sk{let's only provide references at the start of chapters and in the
  bib section of consistency. this makes it read more like a book
  rather than a paper.}
\fi



\subsection{Performance Guarantees}

%\sk{why not just do this for fixed design? if we have $2N$ total
%  samples, then, on the support points, why not take $\lceil \rho(s,a)
%  N \rceil$, which is at most $2N$ samples. Then the covariance on
%  these points is bigger than $d N$. And the guarantee for fixed
%  design regression should be immediate. Then we can just cite
%  the self-norm sum in the appendix for the proof.}

Now we explain how we can construct a dataset $\Dcal_h$ for $h = 0,\dots, H-1$ using the D-optimal design $\rho$ and the generative model:

%\wen{combine bullet point 1 and 2 --- get rid of the $D_{s,a}$ notation.}
\begin{itemize}
\item At $h$, for each $s,a\in\text{support}(\rho)$, we sample $n_{s,a} := \lceil \rho(s,a) N \rceil$ many next states independently from $P_h(\cdot | s,a)$; combine all $(s,a,r(s,a),s')$ and denote the whole dataset as $\Dcal_h$ %, and denote the set $\Dcal_{s,a} = \{{s^i}' \}_{i=1}^{\lceil\rho(s,a) N \rceil}$ where ${s^i}' \sim P_h(\cdot | s,a)$. 
%\item Set $\Dcal_h = \cup_{s,a\in\text{support}(\rho)} \Dcal_{s,a}$. 
\item Repeat for all $h\in [0,\dots, H-1]$ to construct $\Dcal_0,\dots, \Dcal_{H-1}$.
\end{itemize}

%For each $s,a$ such that $\phi(s,a) \in \text{support}(\rho)$ (for simplicity, we abuse notation and write $s,a\in\text{support}(\rho)$), we sample in total $n_{s,a} := \left\lceil \rho(s,a) N  \right\rceil$ many next states, denoting $\Dcal_{s,a} = \{{s^i}' \}_{i=1}^{n_{s,a}}$ with ${s^i}'\sim P_h(\cdot | s,a)$. Thus, our dataset $\Dcal_{h} := \cup_{s,a\in\text{support}(\rho)} \Dcal_{s,a}$. We repeat the same procedure for all $h$. 



%For each $s,a$ such that $\phi(s,a) \in \text{support}(\rho)$, we sample in total $n_{s,a}$ many next states, denoting $\Dcal_{s,a} = \{{s^i}' \}_{i=1}^{n_{s,a}}$ with ${s^i}'\sim P(\cdot | s,a)$. We set $n_{s,a}$ as follows: $$n_{s,a} =  \left\lceil \frac{ c \rho(s,a) g(\rho) }{\epsilon^2} \ln(|\Scal||\Acal|/\delta) \right\rceil,$$ where $c$ is some positive constant.
%Denote $\Lambda = \sum_{s,a\in \text{support}(\rho)  }n_{s,a} \phi(s,a)\phi(s,a)^{\top} $, we can show that 
%\begin{align}
%\label{eq:lambda_property}
%\Lambda \succcurlyeq \frac{c g(\rho)}{\epsilon^2} \ln(|\Scal||\Acal|/\delta) \Sigma,
%\end{align} which also implies that $\text{rank}(\Lambda) = d$ since $\Sigma$ has rank $d$.

The key property of the dataset $\Dcal_h$ is that the empirical covariance matrix $\sum_{s,a\in\Dcal_h} \phi(s,a)\phi(s,a)^{\top}$ is full rank. Denote $\Lambda_h = \sum_{s,a\in \Dcal_h  }\phi(s,a)\phi(s,a)^{\top} $, we can verify that 
\begin{align}
\label{eq:lambda_property}
\Lambda_h  = \sum_{s,a \in \Dcal} \phi(s,a)\phi(s,a)^{\top}   \succcurlyeq N \Sigma
\end{align} where the inequality comes from the fact that in $\Dcal_h$, for each $s,a\in\text{support}(\rho)$, we have $\lceil \rho(s,a) N \rceil$ many copies of it. 
%\wen{inequality as it's ceiling.}which also implies that $\text{rank}(\Lambda) = d$ since $\Sigma$ has rank $d$. More importantly, 
The D-optimal design ensures that $\Lambda$ covers all $\phi(s,a)$ in the sense that $\max_{s,a} \phi(s,a)^{\top} \Lambda_h^{-1} \phi(s,a)^{\top} \leq d$ due to the property of the D-optimal design. This is the key property that ensures  the solution of the least squares on $\Dcal_h$ is accurate globally.  

Now we state the main sample complexity bound theorem for LSVI. 
\begin{theorem} [Sample Complexity of LSVI]\label{them:main_lsvi_bell_complete}
Suppose our features satisfy the linear Bellman completion property.
Fix $\delta \in (0, 1)$ and
  $\epsilon \in (0,1)$.  Set parameter
  $N := \left\lceil \frac{ 64 H^6 d^2 {\ln(1/\delta)}}{\epsilon^2}
  \right\rceil$.
  With probability at least $1-\delta$, Algorithm~\ref{alg:lsvi}
  outputs $\widehat\pi$ such that:
\begin{align*}
\mathbb{E}_{s\sim \mu} V^\star_0(s) - \mathbb{E}_{s\sim \mu} V^{\widehat\pi}_0(s) \leq  \epsilon,
\end{align*} with total number of samples $H \left( d^2 +   \frac{ 64H^6 d^2 {\ln(1/\delta)}  }{\epsilon^2}    \right)$.
\end{theorem}


%\wen{just refer the equation in the algorithm.}
%Now let us consider the following ridge least square regression problems on $\Dcal_h$:
%\begin{align}
%\hat\theta := \argmin_{\theta} \sum_{s,a,s'\in\Dcal_h}  \left(  \theta^{\top} \phi(s,a) -  r(s,a) - V({s'})  \right)^2 ,
%\label{eq:ls_bc}
%\end{align} where for now  we assume $V(s') := \max_{a' \in \Acal } w^{\top} \phi(s',a')$ for some $w$ that is independent of the randomness in $\Dcal_{h}$ here. Using the linear Bellman completion assumption, we know that $\Tcal_h(w)^{\top} \phi(s,a) = r(s,a) + \mathbb{E}_{s'\sim P_h(s,a)} \max_{a'} w^{\top}\phi(s',a')$, and  $\theta^\star := \Tcal_h(w)$  is the Bayes optimal solution of the above least square problem.   The following theorem quantifies the quality of the learned linear predictor $\hat\theta$.


%\sk{we should give the performance guarantee here. notice the change
%  section titles.}

%\sk{let's move this into the analysis section}

%\wen{just refer the equation in the algorithm.}
%Now let us consider the following ridge least square regression problems on $\Dcal_h$:
%\begin{align}
%\hat\theta := \argmin_{\theta} \sum_{s,a,s'\in\Dcal_h}  \left(  \theta^{\top} \phi(s,a) -  r(s,a) - V({s'})  \right)^2 ,
%\label{eq:ls_bc}
%\end{align} where for now  we assume $V(s') := \max_{a' \in \Acal } w^{\top} \phi(s',a')$ for some $w$ that is independent of the randomness in $\Dcal_{h}$ here. Using the linear Bellman completion assumption, we know that $\Tcal_h(w)^{\top} \phi(s,a) = r(s,a) + \mathbb{E}_{s'\sim P_h(s,a)} \max_{a'} w^{\top}\phi(s',a')$, and  $\theta^\star := \Tcal_h(w)$  is the Bayes optimal solution of the above least square problem.   The following theorem quantifies the quality of the learned linear predictor $\hat\theta$.




\subsection{Analysis}

\iffalse
\begin{theorem}\label{thm:design_lr}Fix $(\delta, \epsilon)$. Denote $\hat{\theta}$ as the least square solution of Eq.~\ref{eq:ls_bc} and assume $\max_{s} | V(s) | \leq W \in \mathbb{R}^+$. %Set $n_{s,a} = \left\lceil \frac{8W^2 \rho(s,a) g(\rho) }{\epsilon^2} \ln(|\Scal||\Acal|/\delta) \right\rceil$.
With probability at least $1-\delta$, we have:
\begin{align*}
\forall s,a \in \Scal\times\Acal: \left\langle \hat{\theta} - \theta^\star, \phi(s,a)  \right\rangle \leq 2W \sqrt{ 2 d \ln(|\Scal| |\Acal| / \delta) / N  }.
\end{align*}
\end{theorem}
\textbf{Remark} Note that the above theorem holds for all $s,a$, i.e., $\hat\theta$ is accurate globally due to the property of $\Lambda_h$. Based on Theorem~\ref{thm:design_lr}, we can see that in order to achieve $\epsilon$ approximation error in regression, we just need to set $N = \frac{8W^2 d \ln(|\Scal||\Acal| / \delta)}{\epsilon^2}$ (or equivalently, $n_{s,a} := \frac{8W^2 d \rho(s,a) \ln(|\Scal||\Acal| / \delta)}{\epsilon^2}$).

\begin{proof} 
Given the D-optimal design $\rho$, recall that we define $\Sigma = \mathbb{E}_{s,a\sim \rho} \phi(s,a) \phi(s,a)^{\top}$.

%Since $\Lambda$ is full rank, $\hat\theta$ has a closed-form solution:
%The closed-form solution of the ridge regression is in the following form:
%\begin{align*}
%\hat\theta := \Lambda^{-1} \sum_{s,a\in\text{support}(\rho)}\sum_{s'\in \Dcal_{s,a}} \phi(s,a) (r(s,a) + V(s')).
%\end{align*} Note $r(s,a) + \EE_{s'\sim P_h(s,a)}\left[ V(s') \right] = (\theta^\star)^{\top} \phi(s,a)$. Denote $\epsilon_{s,a,i} = (\theta^\star)^{\top} \phi(s,a) -  (r(s,a) + V(s')) $, we have $\EE[\epsilon_{s,a,i}] = 0$, and $\{\epsilon_{s,a,i}\}$ are independent. Now we can compute $\hat\theta - \theta^\star$ as follows:
%\begin{align*}
%\hat\theta - \theta^\star &= \Lambda^{-1} \sum_{s,a\in\text{support}(\rho)}\sum_{s'\in \Dcal_{s,a}} \phi(s,a) (\epsilon_{s,a,i} + \phi(s,a)^{\top} \theta^\star) - \theta^\star \\
%& = \Lambda^{-1} \sum_{s,a\in\text{support}(\rho)}\sum_{s'\in \Dcal_{s,a}} \phi(s,a) \epsilon_{s,a,i} + \theta^\star - \theta^\star  - \lambda \Lambda^{-1} \theta^\star \\
%& = \Lambda^{-1} \sum_{s,a\in\text{support}(\rho)}\sum_{s'\in \Dcal_{s,a}} \phi(s,a) \epsilon_{s,a,i} - \lambda \Lambda^{-1} \theta^\star. 
%\end{align*}
%Multiple $\Lambda^{1/2}$ on both sides, we have:
%\begin{align*}
%\Lambda^{1/2} (\hat\theta - \theta^\star) = \Lambda^{-1/2} \sum_{s,a\in\text{support}(\rho)}\sum_{s'\in \Dcal_{s,a}} \phi(s,a) \epsilon_{s,a,i} - \lambda \Lambda^{-1/2} \theta^\star.
%\end{align*}Note that $|\epsilon_{s,a,i}| \leq ( H + 1 + W ) \leq 2(H+W)$. Via the self-normalized Martingale bound Lemma~\ref{lemma:self_norm}, we know that with probability at least $1-\delta$:
%\begin{align*}
%\left\|\Lambda^{-1/2} \sum_{s,a\in\text{support}(\rho)}\sum_{s'\in \Dcal_{s,a}} \phi(s,a) \epsilon_{s,a,i}\right\|_2^2 \leq 4(H+W)^2 \ln\left( \frac{ \det( \Lambda )  / \det(\lambda I) }{\delta}  \right) \leq  4(H+W)^2 d \ln\left( 1 +    \right)
%\end{align*} 


Since $\max_{s} |V(s)| \leq W$, we have that for any $(s,a, s'^i)$, $\left\lvert \mathbb{E}_{s'\sim P_h(s,a)} V(s') - V(s'^i)    \right\rvert \leq 2W$, and $V(s'^i)$ is an unbiased estimate of $\mathbb{E}_{s'\sim P(s,a)} V(s')$. Thus based on Lemma~\ref{lemma:least_square}, for a fixed direction $\phi(s,a)$, with probability at least $1-\delta$, we have:
\begin{align*}
\langle \hat\theta - \theta^\star,  \phi(s,a)  \rangle \leq  2W \sqrt{2 \| \phi(s,a) \|^2_{\Lambda^{-1}} \ln(1/\delta) }.
\end{align*} Apply a union bound over $\Scal\times\Acal$, we have that with probability at least $1-\delta$, for all $s,a\in\Scal\times\Acal$,
\begin{align*}
\langle \hat\theta - \theta^\star,  \phi(s,a)  \rangle \leq  2W \sqrt{2 \| \phi(s,a) \|^2_{\Lambda^{-1}} \ln(|\Scal||\Acal|/\delta) }.
\end{align*}

Using the property of the $\Lambda \geq N\Sigma$ (Eq.~\ref{eq:lambda_property}), we must have:
\begin{align*}
\| \phi(s,a) \|^2_{\Lambda^{-1}} \leq  \phi(s,a)^{\top} \Sigma^{-1} \phi(s,a) / N \leq d / N, \forall s,a,
% \frac{\epsilon^2}{ 8W^2 \ln(|\Scal||\Acal|/\delta) g(\rho) } \phi(s,a) \Sigma^{-1} \phi(s,a) \leq \frac{\epsilon^2}{ 8W^2\ln(|\Scal||\Acal|/\delta)}.
\end{align*} where the last inequality uses the property of the D-optimal design: $\max_{s,a} \|\phi(s,a)\|^2_{\Sigma^{-1}} \leq d$.    
Thus, with probability at least $1-\delta$, for all $s,a$, we have:
\begin{align*}
\langle \hat{\theta} - \theta^\star, \phi(s,a) \rangle \leq 2W \sqrt{ 2 d \ln(|\Scal| |\Acal| / \delta) / N  },
\end{align*} which concludes the proof.
\end{proof}

\begin{lemma}\label{lemma:least_square} Fix $\delta \in (0,1)$. Consider the following linear regression setting.  Given a set of $N$ data points $\{x_i, y_i\}_{i=1}^N$ with $x_i \in \mathbb{R}^d$ and $y_i \in \mathbb{R}$, where $y_i = (w^\star)^{\top} x_i + \epsilon_i$ with $\mathbb{E}[\epsilon_i] =0$, $| \epsilon_i | \leq \alpha \in \mathbb{R}^+$, and $\{\epsilon_i\}$ are independent from each other.  Further assume that $\Lambda := \sum_{i=1}^N x_i x_i^{\top}$ is full rank. Denote $\widehat{w}$ as the linear regression solution, i.e., $\widehat{w} := \arg\min_{w} \sum_{i=1}^N (w^{\top} x_i - y_i )^2$. Consider a fixed $x\in\mathbb{R}^d$, with probability at least $1-\delta$, we have:
\begin{align*}
\left\langle \widehat{w} - w^\star, x  \right\rangle \leq \sqrt{ 2 \sigma^2 \| x  \|^2_{\Lambda^{-1}}  \ln(1/\delta)  }.
\end{align*}
\end{lemma}
\begin{proof} Since $\widehat{w}$ is the ordinary least square solution, we have $\widehat{w} = \Lambda^{-1} \sum_{i=1}^N x_i y_i$.  
\begin{align*}
\left( \widehat{w} - w^\star\right)^{\top} x =\left(  \Lambda^{-1} \sum_{i=1}^N x_i (x_i^{\top} w^\star + \epsilon_i) - w^\star \right)^{\top} x =x^{\top}  \Lambda ^{-1}\sum_{i=1}^N x_i \epsilon_i 
\end{align*} Since $\epsilon_i$ is a $\sigma$-subGaussian random variables (a random variable with zero mean and bounded norm is a sub-Gaussian random variable), via Lemma~\ref{lemma:sub_gaussian_property_2}, we have that $x^{\top} \Lambda^{-1} \sum_{i=1}^N x_i \epsilon_i$ being a $\sqrt{  \sum_{i=1}^N (x^{\top} \Lambda^{-1} x_i )^2 \sigma^2 }$-subGaussian random variable.  Thus via the tail property of a subGaussian random variable shown in Theorem~\ref{them:sub_gaussian_property_1}, we have:
\begin{align*}
\mathrm{Pr}\left(  \left( \widehat{w} - w^\star\right)^{\top} x \geq  \xi  \right) \leq \exp\left( -\frac{\xi^2}{ 2\sigma^2 \sum_{i=1}^N (x^{\top}\Lambda^{-1} x_i)^2  } \right)
\end{align*}Set  $\exp\left( -\frac{\xi^2}{ 2\sigma^2 \sum_{i=1}^N (x^{\top}\Lambda^{-1} x_i)^2  } \right) = \delta$, and note the fact that $\sum_{i=1}^N (x^{\top} \Lambda^{-1} x_i)^2 =  x^{\top} \Lambda^{-1} \sum_{i=1}^N x_i x_i^{\top} \Lambda^{-1} x    = x^{\top} \Lambda^{-1} x$, we conclude the proof. 
\end{proof}



%Now we are ready to analyze the LSVI algorithm.  We first present the main theorem for the LSVI algorithm. 
%\begin{theorem} [Sample Complexity of LSVI]\label{them:main_lsvi_bell_complete}Fix $\delta \in (0, 1/H)$ and $\epsilon \in (0,1/(2H))$.  For $s,a \in \text{support}(\rho)$, set parameter  $n_{s,a} := \left\lceil \frac{ 32H^2 \rho(s,a) d }{\epsilon^2} \ln(|\Scal||\Acal| / \delta)\right\rceil$. With probability at least $1-H\delta$, Algorithm~\ref{alg:lsvi} outputs  $\widehat\pi$ such that:
%\begin{align*}
%\mathbb{E}_{s\sim \mu} V^\star_0(s) - \mathbb{E}_{s\sim \mu} V^{\widehat\pi}_0(s) \leq  2H^2 \epsilon,
%\end{align*} with total number of samples $O\left(  H  d^2 +   \frac{ H^3 d  }{\epsilon^2} \ln(|\Scal||\Acal| / \delta)  \right)$.
%\end{theorem}

Below we first present some key lemmas.
\wen{use T notation and ell infty norms, combine 3.6 and 3.7 together..}
Let us denote $\widehat{Q}_h(s,a) : = \theta_h^{\top} \phi(s,a)$ where $\theta_h$ is the learned Q functions in Alg.~\ref{alg:lsvi}. Our goal is to show that for all $s,a,h$, we have $\widehat{Q}_h(s,a)$ being close to $Q^\star_h(s,a)$. Then, the induced greedy policy $\widehat\pi_h(s) := \arg\max_{a} \widehat{Q}_h(s,a)$ will be near optimal. The following lemma bounds the difference between $\widehat{Q}_h(s,a)$ and $Q^\star_h(s,a)$.
\fi

To prove the theorem, we first show that if we had $\{\widehat{Q}_{h}\}_{h}$ such that the Bellman residual $\| \widehat{Q}_h- \Tcal_h\widehat{Q}_{h+1} \|_{\infty}$ is small, then the performance of the greedy policies with respect to $\widehat{Q}_h$ is already near optimal. Note that this result is general and has nothing to do with the LSVI algorithm.

\begin{lemma} \label{lem:perturbation_Q}Assume that for all $h$, we have $\left\| \widehat{Q}_h - \Tcal_{h+1} \widehat{Q}_{h+1}  \right\|_{\infty} \leq \epsilon$. Then we have:
\begin{enumerate}
\item Accuracy of $\widehat{Q}_h$: for all $h$:  $\left\| \widehat{Q}_h - Q^\star_h  \right\|_{\infty} \leq (H-h)\epsilon$, 
\item Policy performance: for $\widehat\pi_h(s) := \argmax_{a} \widehat{Q}_h(s,a)$, we have $\left\lvert V^{\widehat\pi} - V^\star  \right\rvert \leq 2 H^2 \epsilon$.
\end{enumerate}
\end{lemma}

\begin{proof}
The proof of this lemma is elementary, which is analog to what we have proved in Value Iteration in the discounted setting. For completeness, we provide a proof here. 

Starting from $Q_{H}(s,a) = 0, \forall s,a$, we have $\Tcal_{H-1} Q_H = r$ by definition. The condition implies that $\|\widehat{Q}_{H-1} - r  \|_{\infty} \leq \epsilon$, which means that $\|\widehat{Q}_{H-1} - Q^\star_{H-1}  \|_{\infty} \leq \epsilon$. This proves the base case. 

Our inductive hypothesis is that $ \| \widehat{Q}_{h+1} -  Q^\star_{h+1} \|_{\infty} \leq (H - h-1)\epsilon$. Note that:
\begin{align*}
\lvert \widehat{Q}_h(s,a) - Q^\star_h(s,a)  \rvert &\leq \lvert \widehat{Q}_h(s,a) - \Tcal_h \widehat{Q}_{h+1}(s,a)  \rvert + \lvert \Tcal_h \widehat{Q}_{h+1}(s,a) - Q^\star_h(s,a) \rvert  \\
& \leq \epsilon + \lvert \Tcal_h \widehat{Q}_{h+1}(s,a) -   \Tcal_h Q^\star_{h+1}(s,a)\rvert \leq \epsilon + (H - h - 1) \epsilon = (H - h) \epsilon,
\end{align*} which concludes the proof for the first claim. 

For the second claim, Starting from time step $H-1$,  for any $s$, we have:
\begin{align*}
 V^{\widehat\pi}_{H-1}(s) -  V^\star_{H-1}(s)& =  Q^{\widehat\pi}_{H-1}(s,\widehat\pi_{H-1}(s)) - Q^\star_{H-1}(s,\pi^\star(s))   \\
& =  Q^{\widehat\pi}_{H-1}(s,\widehat\pi_{H-1}(s)) - Q^\star_{H-1}(s, \widehat\pi_{H-1}(s)) + Q^\star_{H-1}(s, \widehat\pi_{H-1}(s))-  Q^\star_{H-1}(s,\pi^\star(s))  \\
& =  Q^\star_{H-1}(s, \widehat\pi_{H-1}(s))-  Q^\star_{H-1}(s,\pi^\star(s))   \\
& \geq Q^\star_{H-1}(s, \widehat\pi_{H-1}(s)) - \widehat{Q}_{H-1}(s, \widehat\pi_{H-1}(s))  + \widehat{Q}_{H-1}(s, \pi^\star(s))  - Q^\star_{H-1}(s,\pi^\star(s)) \\
& \geq 2\epsilon,
\end{align*} where the third equality uses the fact that $Q^{\widehat\pi}_{H-1}(s,a) = Q^\star_{H-1}(s,a) = r(s,a)$, the first inequality uses the definition of $\widehat{\pi}_{H-1}$ and $\widehat{Q}_{H-1}(s, \widehat\pi_{H-1}(s)) \geq \widehat{Q}_{H-1}(s, a),\forall a$.
This concludes the base case. For time step $h+1$, our inductive hypothesis is defined as $V^{\widehat\pi}_{h+1}(s) -  V^\star_{h+1}(s) \geq  - 2 (H - h - 1) H \epsilon$. For time step $h$, we have:
\begin{align*}
V^{\widehat\pi}_{h}(s) -  V^\star_{h}(s)& =  Q^{\widehat\pi}_{h}(s,\widehat\pi_{h}(s)) - Q^\star_{h}(s,\pi^\star(s)) \\
& = Q^{\widehat\pi}_{h}(s,\widehat\pi_{h}(s)) -  Q^\star_h(s, \widehat\pi_{h}(s)) + Q^\star_h(s, \widehat\pi_{h}(s)) - Q^\star_{h}(s,\pi^\star(s)) \\
& = \mathbb{E}_{s'\sim P_h(s, \widehat\pi_h(s))}\left[ V^{\widehat\pi}_{h+1}(s') - V^\star_{h+1}(s') \right] + Q^\star_h(s, \widehat\pi_{h}(s)) - Q^\star_{h}(s,\pi^\star(s)) \\
& \geq - 2 (H - h - 1) \epsilon  + Q^\star_h(s, \widehat\pi_{h}(s)) -  \widehat{Q}_h(s, \widehat\pi_{h}(s)) +  \widehat{Q}_h(s, \pi^\star_{h}(s)) -  Q^\star_{h}(s,\pi^\star(s)) \\
& \geq - 2(H-h-1) H \epsilon  - 2(H-h)\epsilon \geq - 2(H-h) H \epsilon.
%& \geq -2(H-h) \epsilon.
\end{align*}
This concludes that for any $s$, at time step $h =0$, we have $V^{\widehat\pi}_{0}(s) -  V^\star_{0}(s ) \geq -2H^2 \epsilon$.
\end{proof}

To conclude the proof, what we left to show is that the $\widehat{Q}_h$ that is returned by LSVI satisfies the condition in the above lemma.  Note that $\widehat{Q}_h(s,a) = \hat\theta_h^{\top} \phi(s,a)$, and $\Tcal_{h} \widehat{Q}_{h+1}$ is indeed the Bayes optimal solution of the least squares in Eq.~\ref{eq:ls_bc}, and via the Bellman completion assumption, we have $\Tcal_h \widehat{Q}_{h+1}(s,a) = \Tcal_h(\hat\theta_{h+1})^{\top} \phi(s,a), \forall s,a$. With the constructed $\Dcal_h$ based on the D-optimal design, Linear regression immediately gives us a generalization bound on $\|\widehat{Q}_h - \Tcal_h \widehat{Q}_{h+1}\|_{\infty}$. The following theorem formalize the above statement. 

\begin{lemma}\label{lemma:ols_lsvi}Fix $\delta \in (0,1)$ and $\epsilon \in (0,1)$, set $N = \left\lceil \frac{ 16H^2d^2  {\ln(H/\delta)}  }{\epsilon^2}\right\rceil$. With probability at least $1-  \delta$, for all $h$, we have:
\begin{align*}
\forall h: \quad \left\| \widehat{Q}_h - \Tcal_{h} \widehat{Q}_{h+1}  \right\|_{\infty} \leq \epsilon.
\end{align*}
\end{lemma}
\begin{proof}
  The proof uses a standard result for ordinary least squares (see
  Theorem~\ref{thm:ols_fixed_design} in the Appendix). Consider a time
  step $h$. In time step $h$, we perform linear regression from $\phi(s,a)$ to $r(s,a) + \max_{a'} \hat\theta_{h+1}^{\top}\phi(s' ,a')$. Note that the Bayes optimal here is $$\EE_{s'\sim P_h(s,a)}\left[ r(s,a) + \max_{a'} \hat\theta_{h+1}^{\top}\phi(s' ,a')  \right] = \Tcal_h(\hat\theta_{h+1})^{\top} \phi(s,a).$$
  
  %Note that $\hat\theta_h$ is the OLS solution from
 % $\Dcal_h$ with $\Tcal_h(\hat\theta_{h+1})$ as the Bayes optimal
  %solution. 
 Also we can show that the noise
  $\epsilon_{s,a} := \left( r(s,a) + \max_{a'} \widehat{Q}_{h+1}(s',a') - \Tcal_h
    \widehat{Q}_h(s,a) \right)$
  is bounded by $2H$, and also note that the noises are independent,
  and has mean zero:
  $\EE_{s' \sim P_h(s,a) }\left[r(s,a) + \max_{a'}
    \widehat{Q}_{h+1}(s',a') - \Tcal_h \widehat{Q}_h(s,a) \right] =
  0$.
  Using Theorem~\ref{thm:ols_fixed_design}, we have that with
  probability at least $1-\delta$,
\begin{align*}
\left\|  \hat\theta_h - \Tcal_h(\hat\theta_{h+1}) \right\|^2_{\Lambda_h} \leq 4H^2 \left( d + \sqrt{d \ln(1/\delta) } + 2\ln(1/\delta)\right).
\end{align*}
Now for any $s,a$, we must have:
\begin{align*}
\left\lvert (\hat\theta_h - \Tcal_{h}(\hat\theta_{h+1}))^{\top} \phi(s,a) \right\rvert^2 & \leq \left\|  \hat\theta_h - \Tcal_h(\hat\theta_{h+1}) \right\|^2_{\Lambda_h} \| \phi(s,a) \|^2_{\Lambda_h^{-1}} \leq \left\|  \hat\theta_h - \Tcal_h(\hat\theta_{h+1}) \right\|^2_{\Lambda_h} \frac{d}{N}  \\
& \leq  4H^2 \frac{ d^2 + d^{1.5} \sqrt{\ln(1/\delta)} + 2d\ln(1/\delta) }{N} \leq \frac{16H^2 d^2 \ln(1/\delta)}{N},
\end{align*} which implies that:
\begin{align*}
\left\| \widehat{Q}_h - \Tcal_{h} \widehat{Q}_{h+1} \right\|_{\infty} = \max_{s,a }\left\lvert (\hat\theta_h - \Tcal_{h}(\hat\theta_{h+1}))^{\top} \phi(s,a) \right\rvert \leq \frac{ 4H d \sqrt{\ln(1/\delta)} }{\sqrt{N}}.
\end{align*}
Set the right hand side to be $\epsilon$, we have $N = \frac{16H^2d^2 { \ln(1/\delta)}}{\epsilon^2}$.

Finally, apply union bound over all $h = 0, \dots, H-1$, we conclude the proof. 
\end{proof}

\iffalse
\begin{lemma}[Accuracy of $\widehat{Q}$] \label{lemma:Q_estimate} Fix $\delta \in (0,1/H)$ and $\epsilon\in (0,1)$. Set $n_{s,a} = \left\lceil \frac{ 32H^2 \rho(s,a) d  }{\epsilon^2} \ln(|\Scal||\Acal| / \delta)  \right\rceil$. With probability $1-H\delta$, for all $s,a\in\Scal\times\Acal$ and $h \in [H]$, we have:
\begin{align*}
\left\lvert \widehat{Q}_h(s,a) - Q^\star_h(s,a) \right\rvert \leq  (H-h)\epsilon.
\end{align*}
\end{lemma}
\begin{proof} 
We first start from $h = H-1$. In the $H-1$ step, we are simply performing linear regression from $s,a$ to reward $r(s,a)$, with the dataset generated via $\rho$ in the way described in Theorem~\ref{thm:design_lr}. Since $ r(s,a)$ is linear with respect to $\phi(s,a)$, $r(s,a)$ is deterministic and $r(s,a) \in [0,1]$, and the data matrix $\Lambda$ in the ordinary least square is full rank, we must have:
\begin{align*}
\left\lvert \theta_{H-1}^{\top} \phi(s,a) - r(s,a)\right\rvert  = 0, \forall s,a.
\end{align*} This also means that $\theta_{H-1}^{\top} \phi(s,a) \in [0,1]$.

Now we consider time step $H-2$. The regression target at $H-2$ is in the form of $r(s,a) + \max_{a'} \theta_{H-1}^{\top} \phi(s',a')$, and  $r(s,a) + \max_{a'} \theta_{H-1}^{\top} \phi(s',a') \in [0, 2]$. Also note that $\Tcal_{H-2}(\theta_{H-1})$ is the Bayes optimal solution of the regression problem at time step $H-2$.
 Thus with $n_{s,a} \geq  \left\lceil \frac{ 8 \rho(s,a) d }{\epsilon^2} \ln(|\Scal||\Acal| / \delta) \right\rceil$, via Theorem~\ref{thm:design_lr}, we must have that with probability at least $1-\delta$, for all $s,a$:
\begin{align*}
\left\lvert \theta_{H-2}^{\top} \phi(s,a) -  \Tcal_{H-2}( \theta_{H-1} )^{\top} \phi(s,a)  \right\rvert \leq \epsilon.
\end{align*} 
Using the definition $\Tcal_{H-2}$, we have $\Tcal_{H-2}(\theta_{H-1})^{\top} \phi(s,a) = r(s,a) + \mathbb{E}_{s'\sim P_{H-2}(s,a)} \max_{a' }\theta_{H-1}^{\top} \phi(s',a') = r(s,a) + \mathbb{E}_{s'\sim P_{H-2}(s,a)} \max_{a' } r(s',a') := Q^\star_{H-2}(s,a)$, which implies:
\begin{align*}
\left\lvert \theta_{H-2}^{\top} \phi(s,a) -  Q^\star_{H-2}(s,a)  \right\rvert \leq \epsilon.
\end{align*} This concludes the base case. 


%Denote $\widehat{Q}_h(s,a) :  = \theta_h^{\top} \phi(s,a)$, we have $\left\lvert \widehat{Q}_{H-1}(s,a) - Q^\star_{H-1}(s,a)   \right\rvert \leq \epsilon$. This concludes the base case. 

Now our inductive hypothesis is that for time step $h+1$, we have $\left\lvert \widehat{Q}_{h+1}(s,a) - Q^\star_{h+1}(s,a)  \right\rvert \leq \epsilon_{h+1} : = (H-h-1) \epsilon$. The inductive hypothesis immediately implies that:
\begin{align*}
\left\lvert V_{h+1}(s) - V^\star_{h+1}(s)   \right\rvert \leq \max_{a} \left\lvert \widehat{Q}_{h+1}(s,a) - Q^\star_{h+1}(s,a)  \right\rvert \leq \epsilon_{h+1}, \forall s,
\end{align*} where the inequality uses the fact that $ \left\lvert \max_{a} \widehat{Q}_{h+1}(s,a) - \max_{a} Q^\star_{h+1}(s,a)  \right\rvert \leq \max_{a} \left\lvert \widehat{Q}_{h+1}(s,a) - Q^\star_{h+1}(s,a)  \right\rvert$.

Now we move to time step $h$. At time step $h$, the regression target is in the form of $r(s,a) + V_{h+1}(s')$ and we have $| V_{h+1}(s) | \leq V^\star_{h+1}(s) + \epsilon_{h+1} \leq  H + H \epsilon \leq 2H$ (since we set $\epsilon \in [0,1]$). %Denote $\bar\theta_h := \Tcal_h( \theta_{h+1})$, namely, for all $s,a$, we have: $\bar\theta_{h}^{\top} \phi(s,a) = r(s,a) + \mathbb{E}_{s'\sim P(s,a)} \max_{a'} \theta_{h+1}^{\top} \phi(s',a')$.  
Similarly, note that $\Tcal_{h}(\theta_{h+1})$ is the Bayes optimal solution of the regression problem at time step $h$.
With $n_{s,a} = \left\lceil \frac{32 H^2  \rho(s,a) d}{\epsilon^2} \cdot \ln(|\Scal||\Acal| / \delta)   \right\rceil$, via Theorem~\ref{thm:design_lr}, we have that with probability at least $1-\delta$,
\begin{align*}
\left\lvert  \theta_h^{\top} \phi(s,a) - \Tcal_{h}(\theta_{h+1})^{\top} \phi(s,a)   \right\rvert \leq \epsilon, \forall s,a.
\end{align*} Thus, we have:
\begin{align*}
\left\lvert \widehat{Q}_h(s,a) - Q^\star_h(s,a)  \right\rvert  & \leq \left\lvert \widehat{Q}_h(s,a) - \Tcal_{h}(\theta_{h+1})^{\top}\phi(s,a)  \right\rvert + \left\lvert  \Tcal_{h}(\theta_{h+1})^{\top} \phi(s,a) - Q^\star_h(s,a)  \right\rvert \\
& \leq \epsilon + \left\lvert  \Tcal_{h}(\theta_{h+1})^{\top} \phi(s,a) - Q^\star_h(s,a)  \right\rvert \\
& \leq \epsilon +  \mathbb{E}_{s'\sim P_h(s,a)}  \max_{a'} \left\lvert \theta_{h+1}^{\top} \phi(s',a')  - Q^\star_h(s',a') \right\rvert \leq \epsilon + \epsilon_{h+1} = (H - h)\epsilon,
\end{align*} where the second last inequality uses the inequality that $| \mathbb{E}_{x} f(x) | \leq \mathbb{E}_{x} |f(x)|$ for any random variable $x$ and function $f$, and the inequality $|\max_{x} f(x) - \max_{x} g(x)| \leq \max_x | f(x) - g(x) |$ for any two functions $f$ and $g$.

This concludes the induction. Finally, to conclude the proof, note that we apply Theorem~\ref{thm:design_lr} for all $h \in [H]$. Via a union bound, we see that the probability of the guarantee in Theorem~\ref{thm:design_lr} failing to hold for some $h$ is at most $H\delta$. This concludes the proof. 
%we see that with probability at least $1- H \delta$, we have Theorem~\ref{thm:design_lr} holds for all $h$.
%We prove the lemma for a fixed $(s,a,h)$ triple. 
\end{proof}

With the above lemma, now we can reason about the performance of the policies $\pi_h(s) := \arg\max_{a} \widehat{Q}_h(s,a)$.

\iffalse
\begin{lemma}[Performance of $\widehat\pi$] \label{lemma:policy_error}Denote $\widehat{\pi}:= \{ \widehat\pi_h\}_{h=0}^{H-1}$ where $\pi_h(s) := \arg\max_{a} \theta_{h}^{\top} \phi(s,a)$. Assume that $| \theta_h^{\top} \phi(s,a) - Q^\star_h(s,a)  | \leq (H-h)\epsilon$ for all $h,s,a$,  we have:
\begin{align*}
\mathbb{E}_{s\sim \mu} V^\star_0(s) - \mathbb{E}_{s\sim \mu} V^{\widehat\pi}_0(s) \leq  2H^2 \epsilon.
\end{align*}
\end{lemma}
\begin{proof} Starting from time step $H-1$,  for any $s$, we have:
\begin{align*}
 V^{\widehat\pi}_{H-1}(s) -  V^\star_{H-1}(s)& =  Q^{\widehat\pi}_{H-1}(s,\widehat\pi_{H-1}(s)) - Q^\star_{H-1}(s,\pi^\star(s))   \\
& =  Q^{\widehat\pi}_{H-1}(s,\widehat\pi_{H-1}(s)) - Q^\star_{H-1}(s, \widehat\pi_{H-1}(s)) + Q^\star_{H-1}(s, \widehat\pi_{H-1}(s))-  Q^\star_{H-1}(s,\pi^\star(s))  \\
& =  Q^\star_{H-1}(s, \widehat\pi_{H-1}(s))-  Q^\star_{H-1}(s,\pi^\star(s))   \\
& \geq Q^\star_{H-1}(s, \widehat\pi_{H-1}(s)) - \widehat{Q}_{H-1}(s, \widehat\pi_{H-1}(s))  + \widehat{Q}_{H-1}(s, \pi^\star(s))  - Q^\star_{H-1}(s,\pi^\star(s)) \\
& \geq 2\epsilon,
\end{align*} where the third equality uses the fact that $Q^{\widehat\pi}_{H-1}(s,a) = Q^\star_{H-1}(s,a) = r(s,a)$, the first inequality uses the definition of $\widehat{\pi}_{H-1}$ and $\widehat{Q}_{H-1}(s, \widehat\pi_{H-1}(s)) \geq \widehat{Q}_{H-1}(s, a),\forall a$.
This concludes the base case. For time step $h+1$, our inductive hypothesis is defined as $V^{\widehat\pi}_{h+1}(s) -  V^\star_{h+1}(s) \geq  - 2 (H - h - 1) H \epsilon$. For time step $h$, we have:
\begin{align*}
V^{\widehat\pi}_{h}(s) -  V^\star_{h}(s)& =  Q^{\widehat\pi}_{h}(s,\widehat\pi_{h}(s)) - Q^\star_{h}(s,\pi^\star(s)) \\
& = Q^{\widehat\pi}_{h}(s,\widehat\pi_{h}(s)) -  Q^\star_h(s, \widehat\pi_{h}(s)) + Q^\star_h(s, \widehat\pi_{h}(s)) - Q^\star_{h}(s,\pi^\star(s)) \\
& = \mathbb{E}_{s'\sim P_h(s, \widehat\pi_h(s))}\left[ V^{\widehat\pi}_{h+1}(s') - V^\star_{h+1}(s') \right] + Q^\star_h(s, \widehat\pi_{h}(s)) - Q^\star_{h}(s,\pi^\star(s)) \\
& \geq - 2 (H - h - 1) \epsilon  + Q^\star_h(s, \widehat\pi_{h}(s)) -  \widehat{Q}_h(s, \widehat\pi_{h}(s)) +  \widehat{Q}_h(s, \pi^\star_{h}(s)) -  Q^\star_{h}(s,\pi^\star(s)) \\
& \geq - 2(H-h-1) H \epsilon  - 2(H-h)\epsilon \geq - 2(H-h) H \epsilon.
%& \geq -2(H-h) \epsilon.
\end{align*}
This concludes that for any $s$, at time step $h =0$, we have $V^{\widehat\pi}_{0}(s) -  V^\star_{0}(s ) \geq -2H^2 \epsilon$.
\end{proof}

Combining the above two lemmas we can conclude proof for the final sample complexity of Algorithm~\ref{alg:lsvi}.
\fi
\fi

Now we are ready to conclude the proof for the main theorem. 

\begin{proof}[Proof of Theorem~\ref{them:main_lsvi_bell_complete}]
Using Lemma~\ref{lemma:ols_lsvi}, with $N = \left\lceil \frac{64 H^6 d^2 \ln(H / \delta)} {\epsilon^2} \right\rceil$, we have that $\| \widehat{Q}_h - \Tcal_h \widehat{Q}_{h+1} \|_{\infty} \leq \epsilon / (2H^2)$ for all $h$, with probability at least $1-\delta$. Now apply Lemma~\ref{lem:perturbation_Q}, we immediately have that $| V^{\hat\pi} - V^\star | \leq \epsilon$.

Regarding sample complexity, we have:
%Based on Lemma~\ref{lemma:Q_estimate}, we have that with probability at least $1-H\delta$, we have $\left\lvert \widehat{Q}_h(s,a) - Q^\star_h(s,a)  \right\rvert \leq (H-h)\epsilon$ for all $s,a,h$. Thus, via Lemma~\ref{lemma:policy_error}, we immediately have that $\mathbb{E}_{s\sim \mu} V^\star_0(s) - \mathbb{E}_{s\sim \mu} V^{\widehat\pi}_0(s) \leq  2H^2 \epsilon$.
%To calculate the sample complexity, we note that the total number of samples is upper bounded as:
\begin{align*}
H  \sum_{s,a} \lceil\rho(s,a) N\rceil \leq H \sum_{s,a \in \text{support}(\rho)}\left( 1 + \rho(s,a) N    \right) 
%\sum_{s,a\in\text{support}(\rho)} n_{s,a} & \leq H \sum_{s,a\in\text{support}(\rho)}\left( 1+ \frac{ 32H^2 \rho(s,a) d  }{\epsilon^2} \ln(|\Scal||\Acal| / \delta)  \right) \\
& \leq H \left( d^2 +   \frac{ 64H^6 d^2 {\ln(H/\delta)}  }{\epsilon^2}    \right), %\leq H \left( d^2 +   \frac{ 32H^2 d  }{\epsilon^2} \ln(|\Scal||\Acal| / \delta)   \right), 
\end{align*} where the second  inequality use the support size upper
bound of the D-optimal design $\rho$ (see Lemma~\ref{them:design_rho}).
This completes the proof.
\end{proof}

\section{How Strong is Bellman Completion as a Modeling?}

To be added.

%First, it implies linear $Q^\star$. 

%Second, if we add a feature, we will break the completeness. (to be added..)

\section{Offline Reinforcement Learning}

One notable observation about LSVI is that the algorithm is
non-adaptive, in the sense that it works using a fixed set of observed
transitions and rewards. Hence, it is applicable to the offline
setting discussed in Chapter~\ref{chap:prelims}.

We now discuss two offline objectives: that of learning a near optimal
policy and that of policy evaluation (i.e. evaluating the quality of a
given policy).

We consider the setting where have a $H$ datasets of the form 
$D_h = \{(s_i,a_i,s_i',r(s_i,a_i))\}_{i=1}^N$, where we assume for each $i$
and $h$, that we have independent samples $s'_i \sim P_h(\cdot|s_i,a_i)$. In other words, $D_h$ is
a dataset of observed transitions corresponding to stage $h$, where
each next state has been sampled independently. Note that here we have
not made explicit distributional assumption about how the
$(s_i,a_i)$'s have been generated. The results we present can also be
extended to where we have a fixed data generation distribution over
these quadruples.

It is straight forward to extend the LSVI guarantees to these setting
provided our dataset has coverage in the following sense:

\begin{assumption}\label{assumption:coverage}
(Coverage)
Suppose that for each $h\in [H]$, we have that:
\[
\frac{1}{N} \sum_{(s_i,a_i) \in D_h} \phi(s_i,a_i)
\phi(s_i,a_i)^{\top} \succeq \frac{1}{\kappa}\Sigma
\]
where $\Sigma$ is the D-optimal design covariance (see Equation~\ref{eq:d_design}).
\end{assumption}

\subsection{Offline Learning}

A minor modification of the proof in
Theorem~\ref{them:main_lsvi_bell_complete} leads to the following guarantee:

\begin{theorem} [Sample Complexity of LSVI] 
Suppose that Assumption~\ref{assumption:coverage} holds and that our
features satisfy the linear Bellman completion property. 
Fix $\delta \in (0, 1)$
  and $\epsilon \in (0,1)$.  Set parameter  $N := \left\lceil \frac{ c
      \kappa H^6 d^2 {\ln(1/\delta)}}{\epsilon^2} \right\rceil$, where
  $c$ is an appropriately chosen absolute constant. With probability
  at least $1-\delta$, Algorithm~\ref{alg:lsvi} outputs  $\widehat\pi$
  such that: 
\begin{align*}
\mathbb{E}_{s\sim \mu} [V^\star_0(s)] - \mathbb{E}_{s\sim \mu} [V^{\widehat\pi}_0(s)] \leq  \epsilon.
\end{align*}
\end{theorem}

\subsection{Offline Policy Evaluation}

Here we are interested in question of evaluating some given policy
$\pi$ using the offline data.  For this, we will make a completeness
assumption with respect to $\pi$ as follows:

\begin{algorithm}[t]
\begin{algorithmic}[1]
%\State Compute the D-optimal design $\rho$ (Eq.~\ref{eq:d_design})
\State \textbf{Input}: $\pi$, $\Dcal_0,\dots, \Dcal_{H-1}$ %Set $V_{H}(s) = 0$ for all $s\in\Scal$
\State Set $V_{H}(s) = 0$ for all $s\in \Scal$
\For{$h = H-1 \to 0$}
    %\State  $\forall (s,a) \in \text{support}(\rho)$, i.i.d sample $\lceil N\rho(s,a) \rceil$ many next states $\Dcal_{s,a} : = \{{s'}^i\}_{i=1}^{\lceil \rho(s,a)N \rceil}$ with ${s'}^i \sim P_h(\cdot | s,a)$
    \State Solve least squares 
    \begin{align}
    \widehat{\theta}_{h} = \arg\min_{\theta }  \sum_{s,a,r, s'\in \Dcal_{h}} \left( \theta^{\top} \phi(s,a)  - r - V_{h+1}({s'}) \right)^2 %\label{eq:ls_bc}
    \end{align}  %\label{line:lsvi_regression}
    \State Set $V_{h}(s) = \widehat{\theta}_h^{\top} \phi(s,\pi(s)), \forall s$
\EndFor
\State \textbf{Return:} $\{\widehat{\theta}_h\}_{h=0}^{H-1}$.
\end{algorithmic}
\caption{Least Squares Policy Evaluation}
\label{alg:lspe}
\end{algorithm}

\begin{definition}[Linear Completeness for $\pi$] 
We say the
features $\phi$ satisfy the \emph{policy completeness property for $\pi$}
if for all $\theta \in \mathbb{R}^d$ and
  $(s,a,h) \in \Scal\times\Acal\times[H]$, there exists
  $ w\in\mathbb{R}^d$ such that:
%linear function $f(s,a) :=
%\theta^{\top} \phi(s,a)$ for some $\theta \in \mathbb{R}^d$, we have: 
\begin{align*}
%\forall h\in [H]:  \exists w\in\mathbb{R}^d, \text{s.t., }  
w^{\top} \phi(s,a) = r(s,a) + \mathbb{E}_{s'\sim P_h(s,a)} \theta^{\top} \phi(s',\pi(s')).
\end{align*} 
%As $w$ depends on $\theta$, we use the notation $\Tcal_h: \mathbb{R}^d\mapsto \mathbb{R}^d$ to
%represent such a $w$, i.e., $w := \Tcal_h( \theta )$ in the above equation.  
\end{definition} 

For this case, Algorithm~\ref{alg:lspe}, Least Squares Policy
Evaluation (LSPE), is a modified version of
LSVI for the purposes of estimation; note the algorithm no longer
estimates $V_{h}(s)$ using the greedy policy.
Again, a nearly identical argument to the proof in
Theorem~\ref{them:main_lsvi_bell_complete} leads to the following
guarantee. Here, we set:
\[
\widehat{V} (\mu) = \sum_{s_i \in D_0} \theta_0 \cdot \phi(s_i, \pi(s_i))
\]
where $\theta_0$ is the parameter returned by LSVI.

\begin{theorem} [Sample Complexity of LSPE] 
Suppose that Assumption~\ref{assumption:coverage} holds and that our
features satisfy the linear policy completion property (with respect
to $\pi$). 
Fix $\delta \in (0, 1)$
  and $\epsilon \in (0,1)$.  Set parameter  $N := \left\lceil \frac{ c
      \kappa H^4 d^2 {\ln(1/\delta)}}{\epsilon^2} \right\rceil$, where
  $c$ is an appropriately chosen absolute constant. With probability
  at least $1-\delta$, Algorithm~\ref{alg:lspe} outputs  $\widehat{\theta}_0$
  such that for all $s$,
\[
|V^\pi_0(s) - \widehat{\theta}^\top_0 \phi(s,\pi(s)) | \leq  \epsilon.
\]
\end{theorem}

Note that the above theorem has a sample complexity improvement by a
factor of $H$. This is due to that the analysis is improvable, as we only care about
value accuracy (the first claim in Lemma~\ref{lem:perturbation_Q},
rather than the second, is what is relevant here). We should note that
the sample size bounds presented in this chapter have not been
optimized with regards to their $H$ dependencies.

\section{Bibliographic Remarks and Further Readings}
\label{chapterBC_bib}

The idea of Bellman completion under general function class was introduced in \cite{munos2005error} under the setting of batch RL. For the episodic online learning setting, \citet{zanette2020learning} provided a statistically efficient algorithm under the linear Bellman completion condition, and \cite{jin2021bellman}  proposes a statistically efficient algorithms under the Bellman completion condition with general function approximation.

We refer readers to to \cite{lattimore2020bandit} for a proof of the
D-optimal design;  the idea directly follows from John's theorem (e.g. see~\cite{ball1997elementary,todd2016minimum}). 


%\cite{} extends the the algorithm from \cite{zanette2020learning} to general function class. 

