% Encoding: UTF-8

@inproceedings{munos2003error,
  title={Error bounds for approximate policy iteration},
  author={Munos, R{\'e}mi},
  booktitle={ICML},
  volume={3},
  pages={560--567},
  year={2003}
}

@inproceedings{hao2021online,
  title={Online Sparse Reinforcement Learning},
  author={Hao, Botao and Lattimore, Tor and Szepesv{\'a}ri, Csaba and Wang, Mengdi},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={316--324},
  year={2021},
  organization={PMLR}
}
@inproceedings{osband2014model,
  title={Model-based reinforcement learning and the eluder dimension},
  author={Osband, Ian and Roy, Benjamin Van},
  booktitle={Proceedings of the 27th International Conference on Neural Information Processing Systems-Volume 1},
  pages={1466--1474},
  year={2014}
}

@inproceedings{ayoub2020model,
  title={Model-based reinforcement learning with value-targeted regression},
  author={Ayoub, Alex and Jia, Zeyu and Szepesvari, Csaba and Wang, Mengdi and Yang, Lin},
  booktitle={International Conference on Machine Learning},
  pages={463--474},
  year={2020},
  organization={PMLR}
}
@inproceedings{zhou2021provably,
  title={Provably efficient reinforcement learning for discounted mdps with feature mapping},
  author={Zhou, Dongruo and He, Jiafan and Gu, Quanquan},
  booktitle={International Conference on Machine Learning},
  pages={12793--12802},
  year={2021},
  organization={PMLR}
}
@inproceedings{modi2020sample,
  title={Sample complexity of reinforcement learning using linearly combined model ensembles},
  author={Modi, Aditya and Jiang, Nan and Tewari, Ambuj and Singh, Satinder},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={2010--2020},
  year={2020},
  organization={PMLR}
}

@inproceedings{zhou2021nearly,
  title={Nearly minimax optimal reinforcement learning for linear mixture markov decision processes},
  author={Zhou, Dongruo and Gu, Quanquan and Szepesvari, Csaba},
  booktitle={Conference on Learning Theory},
  pages={4532--4576},
  year={2021},
  organization={PMLR}
}


@article{modi2021model,
  title={Model-free representation learning and exploration in low-rank MDPs},
  author={Modi, Aditya and Chen, Jinglin and Krishnamurthy, Akshay and Jiang, Nan and Agarwal, Alekh},
  journal={arXiv preprint arXiv:2102.07035},
  year={2021}
}

@misc{uehara2021representation,
      title={Representation Learning for Online and Offline RL in Low-rank MDPs}, 
      author={Masatoshi Uehara and Xuezhou Zhang and Wen Sun},
      year={2021},
      eprint={2110.04652},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{Hsu2012RandomDA,
  title={Random Design Analysis of Ridge Regression},
  author={Daniel J. Hsu and S. Kakade and Tong Zhang},
  journal={Foundations of Computational Mathematics},
  year={2012},
  volume={14},
  pages={569-600}
}
@article{jin2021bellman,
  title={Bellman Eluder dimension: New rich classes of RL problems, and sample-efficient algorithms},
  author={Jin, Chi and Liu, Qinghua and Miryoosefi, Sobhan},
  journal={arXiv preprint arXiv:2102.00815},
  year={2021}
}

@inproceedings{zanette2020learning,
  title={Learning near optimal policies with low inherent bellman error},
  author={Zanette, Andrea and Lazaric, Alessandro and Kochenderfer, Mykel and Brunskill, Emma},
  booktitle={International Conference on Machine Learning},
  pages={10978--10989},
  year={2020},
  organization={PMLR}
}

@inproceedings{jiang2018pac,
  author    = {Nan Jiang},
  title     = {{PAC} Reinforcement Learning With an Imperfect Model},
  booktitle = {Proceedings of the Thirty-Second {AAAI} Conference on Artificial Intelligence ({AAAI}-18)},
  pages     = {3334--3341},
  year      = {2018}
}

@inproceedings{dann2018oracle,
title = {On Oracle-Efficient {PAC} Reinforcement Learning with Rich Observations},
author = {Dann, Christoph and Jiang, Nan and Krishnamurthy, Akshay and Agarwal, Alekh and Langford, John and Schapire, Robert E.},
booktitle = {Advances in Neural Information Processing Systems 31},
year = {2018}
}

@article{gretton2012kernel,
  title={A kernel two-sample test},
  author={Gretton, Arthur and Borgwardt, Karsten M and Rasch, Malte J and Sch{\"o}lkopf, Bernhard and Smola, Alexander},
  journal={Journal of Machine Learning Research},
  volume={13},
  number={Mar},
  pages={723--773},
  year={2012}
}

@InProceedings{sandholm2012lossy,
  author    = {Sandholm, Tuomas and Singh, Satinder},
  title     = {Lossy stochastic game abstraction with bounds},
  booktitle = {Proceedings of the 13th ACM Conference on Electronic Commerce},
  year      = {2012},
  pages     = {880--897},
}

@InCollection{ravindran2002model,
  author    = {Ravindran, Balaraman and Barto, Andrew},
  title     = {Model minimization in hierarchical reinforcement learning},
  booktitle = {Abstraction, Reformulation, and Approximation},
  year      = {2002},
  pages     = {196--211},
}

@Article{hester2013texplore,
  author  = {Hester, Todd and Stone, Peter},
  title   = {{TEXPLORE}: real-time sample-efficient reinforcement learning for robots},
  journal = {Machine Learning},
  year    = {2013},
  volume  = {90},
  number  = {3},
  pages   = {385--429},
}

@Article{givan2003equivalence,
  author  = {Givan, Robert and Dean, Thomas and Greig, Matthew},
  title   = {Equivalence notions and model minimization in {M}arkov decision processes},
  journal = {Artificial Intelligence},
  year    = {2003},
  volume  = {147},
  number  = {1},
  pages   = {163--223},
}

@InProceedings{li2006towards,
  author    = {Li, Lihong and Walsh, Thomas J and Littman, Michael L},
  title     = {Towards a unified theory of state abstraction for {MDP}s},
  booktitle = {Proceedings of the 9th International Symposium on Artificial Intelligence and Mathematics},
  year      = {2006},
  pages     = {531--539},
}

@PhdThesis{ravindran2004algebraic,
  author = {Ravindran, Balaraman},
  title  = {An algebraic approach to abstraction in reinforcement learning},
  school = {University of Massachusetts Amherst},
  year   = {2004},
}

@InProceedings{sutton1999policy,
  author    = {Sutton, Richard S and McAllester, David A and Singh, Satinder P and Mansour, Yishay},
  title     = {Policy gradient methods for reinforcement learning with function approximation},
  booktitle = {Advances in Neural Information Processing Systems},
  year      = {1999},
  volume    = {99},
  pages     = {1057--1063},
}

@Article{dietterich2000hierarchical,
  author  = {Dietterich, Thomas G},
  title   = {Hierarchical reinforcement learning with the {MAXQ} value function decomposition},
  journal = {Journal of Artificial Intelligence Research},
  year    = {2000},
  volume  = {13},
  pages   = {227--303},
}

@InCollection{even-dar2003approximate,
  author    = {Even-Dar, Eyal and Mansour, Yishay},
  title     = {Approximate equivalence of {M}arkov decision processes},
  booktitle = {Learning Theory and Kernel Machines},
  year      = {2003},
  pages     = {581--594},
}

@InProceedings{ferns2004metrics,
  author    = {Ferns, Norm and Panangaden, Prakash and Precup, Doina},
  title     = {Metrics for finite {M}arkov decision processes},
  booktitle = {Proceedings of Uncertainty in Artificial Intelligence},
  year      = {2004},
  pages     = {162--169},
}

@InProceedings{taylor2008bounding,
  author    = {Taylor, Jonathan and Precup, Doina and Panagaden, Prakash},
  title     = {Bounding performance loss in approximate {MDP} homomorphisms},
  booktitle = {Advances in Neural Information Processing Systems},
  year      = {2008},
  pages     = {1649--1656},
}

@InProceedings{ferns2006methods,
  author    = {Ferns, Norm and Castro, Pablo Samuel and Precup, Doina and Panangaden, Prakash},
  title     = {Methods for computing state similarity in markov decision processes},
  booktitle = {Proceedings of Uncertainty in Artificial Intelligence},
  year      = {2006},
  pages     = {174-181},
}

@InProceedings{narayanamurthy2007efficientlya,
  author    = {Narayanamurthy, Shravan Matthur and Ravindran, Balaraman},
  title     = {Efficiently {E}xploiting {S}ymmetries in {R}eal {T}ime {D}ynamic {P}rogramming},
  booktitle = {International Joint Conference on Artificial Intelligence},
  year      = {2007},
  pages     = {2556--2561},
}

@Article{whitt1978approximations,
  author    = {Whitt, Ward},
  title     = {{Approximations of dynamic programs, I}},
  journal   = {Mathematics of Operations Research},
  year      = {1978},
  volume    = {3},
  number    = {3},
  pages     = {231--243},
  publisher = {INFORMS},
}

@inproceedings{dudik2011doubly,
  title={Doubly robust policy evaluation and learning},
  author={Dud{\'\i}k, Miroslav and Langford, John and Li, Lihong},
  booktitle={Proceedings of the 28th International Conference on International Conference on Machine Learning},
  pages={1097--1104},
  year={2011},
  organization={Omnipress}
}

@Article{ortner2014selecting,
  author  = {Ortner, Ronald and Maillard, Odalric-Ambrym and Ryabko, Daniil},
  title   = {Selecting {N}ear-{O}ptimal {A}pproximate {S}tate {R}epresentations in {R}einforcement {L}earning},
  journal = {arXiv preprint arXiv:1405.2652},
  year    = {2014},
}

@InProceedings{hallak2013model,
  author    = {Hallak, Assaf and Di-Castro, Dotan and Mannor, Shie},
  title     = {Model selection in markovian processes},
  booktitle = {Proceedings of the 19th ACM SIGKDD Conference on Knowledge Discovery and Data mining},
  year      = {2013},
  pages     = {374--382},
}

@Article{farahmand2011model,
  author    = {Farahmand, Amir-massoud and Szepesv{\'a}ri, Csaba},
  title     = {Model selection in reinforcement learning},
  journal   = {Machine learning},
  year      = {2011},
  volume    = {85},
  number    = {3},
  pages     = {299--332},
  publisher = {Springer US},
}

@InProceedings{bartlett2009regal,
  author       = {Bartlett, Peter L and Tewari, Ambuj},
  title        = {{REGAL}: {A} regularization based algorithm for reinforcement learning in weakly communicating {MDP}s},
  booktitle    = {Proceedings of the 25th Conference on Uncertainty in Artificial Intelligence},
  year         = {2009},
  pages        = {35--42},
  organization = {AUAI Press},
}

@InProceedings{mandel2014offline,
  author    = {Mandel, Travis and Liu, Yun-En and Levine, Sergey and Brunskill, Emma and Popovic, Zoran},
  title     = {Offline policy evaluation across representations with applications to educational games},
  booktitle = {Proceedings of the 13th International Conference on Autonomous Agents and Multi-Agent Systems},
  year      = {2014},
  pages     = {1077--1084},
}

@InProceedings{parr2008analysis,
  author    = {Parr, Ronald and Li, Lihong and Taylor, Gavin and Painter-Wakefield, Christopher and Littman, Michael L},
  title     = {An analysis of linear models, linear value-function approximation, and feature selection for reinforcement learning},
  booktitle = {Proceedings of the 25th International Conference on Machine Learning},
  year      = {2008},
  pages     = {752--759},
}

@Article{ormoneit2002kernel,
  author    = {Ormoneit, Dirk and Sen, {\'S}aunak},
  title     = {Kernel-based reinforcement learning},
  journal   = {Machine learning},
  year      = {2002},
  volume    = {49},
  number    = {2-3},
  pages     = {161--178},
  publisher = {Kluwer Academic Publishers},
}

@InProceedings{ravindran2004approximate,
  author    = {Ravindran, Balaraman and Barto, Andrew},
  title     = {Approximate homomorphisms: {A} framework for nonexact minimization in {M}arkov decision processes},
  booktitle = {Proceedings of the 5th International Conference on Knowledge-Based Computer Systems},
  year      = {2004},
}

@Article{bartlett2003rademacher,
  author    = {Bartlett, Peter L and Mendelson, Shahar},
  title     = {Rademacher and {G}aussian complexities: {R}isk bounds and structural results},
  journal   = {The Journal of Machine Learning Research},
  year      = {2003},
  volume    = {3},
  pages     = {463--482},
  publisher = {JMLR.org},
}

@Article{boutilier2000stochastic,
  author    = {Boutilier, Craig and Dearden, Richard and Goldszmidt, Mois{\'e}s},
  title     = {{S}tochastic dynamic programming with factored representations},
  journal   = {Artificial Intelligence},
  year      = {2000},
  volume    = {121},
  number    = {1},
  pages     = {49--107},
  publisher = {Elsevier},
}

@Article{brafman2003r,
  author    = {Brafman, Ronen I and Tennenholtz, Moshe},
  title     = {R-max-a general polynomial time algorithm for near-optimal reinforcement learning},
  journal   = {The Journal of Machine Learning Research},
  year      = {2003},
  volume    = {3},
  pages     = {213--231},
  publisher = {JMLR.org},
}

@Article{kaelbling1996reinforcement,
  author  = {Kaelbling, Leslie Pack and Littman, Michael L and Moore, Andrew W},
  title   = {Reinforcement {L}earning: {A} {S}urvey},
  journal = {Journal of Artificial Intelligence Research},
  year    = {1996},
  volume  = {4},
  pages   = {237--285},
}

@Book{kearns1994introduction,
  title     = {An {I}ntroduction to {C}omputational {L}earning {T}heory},
  publisher = {MIT Press},
  year      = {1994},
  author    = {Kearns, Michael J and Vazirani, Umesh V},
  isbn      = {9780262111935},
  lccn      = {lc94016588},
  url       = {http://books.google.com/books?id=vCA01wY6iywC},
}

@Article{kearns2002optimal,
  author    = {Kearns, Michael and Singh, Satinder},
  title     = {Near-optimal reinforcement learning in polynomial time},
  journal   = {Machine Learning},
  year      = {2002},
  volume    = {49},
  number    = {2-3},
  pages     = {209--232},
  publisher = {Springer},
}

@InCollection{koltchinskii2000rademacher,
  author    = {Koltchinskii, Vladimir and Panchenko, Dmitriy},
  title     = {Rademacher processes and bounding the risk of function learning},
  booktitle = {High Dimensional Probability II},
  publisher = {Springer},
  year      = {2000},
  pages     = {443--457},
}

@Article{mannor2007bias,
  author    = {Mannor, Shie and Simester, Duncan and Sun, Peng and Tsitsiklis, John N},
  title     = {Bias and variance approximation in value function estimates},
  journal   = {Management Science},
  year      = {2007},
  volume    = {53},
  number    = {2},
  pages     = {308--322},
  publisher = {INFORMS},
}

@InProceedings{farahmand2010error,
  author    = {Farahmand, Amir-massoud and Szepesv{\'a}ri, Csaba and Munos, R{\'e}mi},
  title     = {Error {P}ropagation for {A}pproximate {P}olicy and {V}alue {I}teration},
  booktitle = {Advances in Neural Information Processing Systems},
  year      = {2010},
  pages     = {568--576},
}

@PhdThesis{paduraru2013policy,
  author = {Paduraru, Cosmin},
  title  = {Off-policy {E}valuation in {M}arkov {D}ecision {P}rocesses},
  school = {McGill University},
  year   = {2013},
}

@InProceedings{strehl2005theoretical,
  author       = {Strehl, Alexander L and Littman, Michael L},
  title        = {A theoretical analysis of model-based interval estimation},
  booktitle    = {Proceedings of the 22nd International Conference on Machine learning},
  year         = {2005},
  pages        = {856--863},
  organization = {ACM},
}

@Article{strehl2009reinforcement,
  author    = {Strehl, Alexander L and Li, Lihong and Littman, Michael L},
  title     = {Reinforcement learning in finite {MDP}s: {PAC} analysis},
  journal   = {The Journal of Machine Learning Research},
  year      = {2009},
  volume    = {10},
  pages     = {2413--2444},
  publisher = {JMLR.org},
}

@InProceedings{tewari2006sample,
  author    = {Tewari, Ambuj and Bartlett, Peter L},
  title     = {Sample complexity of policy search with known dynamics},
  booktitle = {Advances in Neural Information Processing Systems},
  year      = {2006},
  volume    = {19},
  pages     = {97--104},
}

@InProceedings{vapnik1992principles,
  author    = {Vapnik, Vladimir},
  title     = {Principles of risk minimization for learning theory},
  booktitle = {Advances in Neural Information Processing Systems},
  year      = {1992},
  pages     = {831--838},
}

@Book{vapnik1998statistical,
  title     = {Statistical learning theory},
  publisher = {Wiley New York},
  year      = {1998},
  author    = {Vapnik, Vladimir},
  volume    = {2},
}

@InProceedings{jiang2014improving,
  author    = {Jiang, Nan and Singh, Satinder and Lewis, Richard},
  title     = {Improving {UCT} planning via approximate homomorphisms},
  booktitle = {Proceedings of the 13th International Conference on Autonomous Agents and Multi-Agent Systems},
  year      = {2014},
  pages     = {1289--1296},
}

@InProceedings{paduraru2008model,
  author    = {Paduraru, Cosmin and Kaplow, Robert and Precup, Doina and Pineau, Joelle},
  title     = {Model-based Reinforcement Learning with State Aggregation},
  booktitle = {8th European Workshop on Reinforcement Learning},
  year      = {2008},
}

@PhdThesis{talvitie2010simple,
  author = {Talvitie, Erik N},
  title  = {Simple Partial Models for Complex Dynamical Systems},
  school = {The University of Michigan},
  year   = {2010},
}

@InProceedings{jong2005state,
  author    = {Jong, Nicholas K and Stone, Peter},
  title     = {State abstraction discovery from irrelevant state variables},
  booktitle = {Proceedings of the 19th International Joint Conference on Artificial Intelligence},
  year      = {2005},
  pages     = {752--757},
}

@Article{singh1994upper,
  author  = {Singh, Satinder and Yee, Richard},
  title   = {An upper bound on the loss from approximate optimal-value functions},
  journal = {Machine Learning},
  year    = {1994},
  volume  = {16},
  number  = {3},
  pages   = {227--233},
}

@InProceedings{dinculescu2010approximate,
  author    = {Dinculescu, Monica and Precup, Doina},
  title     = {Approximate predictive representations of partially observable systems},
  booktitle = {Proceedings of the 27th International Conference on Machine Learning (ICML-10)},
  year      = {2010},
  pages     = {895--902},
}

@Article{talvitie2011learning,
  author  = {Talvitie, Erik and Singh, Satinder},
  title   = {Learning to Make Predictions In Partially Observable Environments Without a Generative Model},
  journal = {Journal of Artificial Intelligence Research (JAIR)},
  year    = {2011},
  volume  = {42},
  pages   = {353--392},
}

@InProceedings{maillard2014how,
  author    = {Maillard, Odalric-Ambrym and Mann, Timothy A and Mannor, Shie},
  title     = {"{H}ow hard is my {MDP}?" {T}he distribution-norm to the rescue},
  booktitle = {Advances in Neural Information Processing Systems},
  year      = {2014},
  pages     = {1835--1843},
}

@Article{seijen2014efficient,
  author  = {van Seijen, Harm and Whiteson, Shimon and Kester, Leon},
  title   = {Efficient abstraction selection in reinforcement learning},
  journal = {Computational Intelligence},
  year    = {2014},
  volume  = {30},
  number  = {4},
  pages   = {657--699},
}

@InProceedings{konidaris2009efficient,
  author    = {Konidaris, George and Barto, Andrew},
  title     = {Efficient {S}kill {L}earning using {A}bstraction {S}election},
  booktitle = {Proceedings of the 21st International Joint Conference on Artificial Intelligence},
  year      = {2009},
}

@Article{cobo2014abstraction,
  author  = {Cobo, Luis C and Subramanian, Kaushik and Isbell, Charles L and Lanterman, Aaron D and Thomaz, Andrea L},
  title   = {Abstraction from demonstration for efficient reinforcement learning in high-dimensional domains},
  journal = {Artificial Intelligence},
  year    = {2014},
  volume  = {216},
  pages   = {103--128},
}

@Article{farahmand2011regularization,
  author    = {Farahmand, Amir-massoud},
  title     = {Regularization in reinforcement learning},
  year      = {2011},
  publisher = {University of Alberta},
}

@Article{agarwal2016corralling,
  author  = {Agarwal, Alekh and Luo, Haipeng and Neyshabur, Behnam and Schapire, Robert E},
  title   = {Corralling a Band of Bandit Algorithms},
  journal = {arXiv preprint arXiv:1612.06246},
  year    = {2016},
}

@PhdThesis{scott2004dyadic,
  author = {Scott, Clayton D},
  title  = {Dyadic decision trees},
  school = {University of Wisconsin at Madison},
  year   = {2004},
}

@InProceedings{ng2003autonomous,
  author    = {Ng, Andrew Y and Kim, H Jin and Jordan, Michael I and Sastry, Shankar and Ballianda, Shiv},
  title     = {Autonomous helicopter flight via reinforcement learning},
  booktitle = {NIPS},
  year      = {2003},
  volume    = {16},
}

@InProceedings{johnson2016malmo,
  author    = {Johnson, Matthew and Hofmann, Katja and Hutton, Tim and Bignell, David},
  title     = {The malmo platform for artificial intelligence experimentation},
  booktitle = {International joint conference on artificial intelligence (IJCAI)},
  year      = {2016},
  pages     = {4246},
}

@Article{brockman2016openai,
  author  = {Brockman, Greg and Cheung, Vicki and Pettersson, Ludwig and Schneider, Jonas and Schulman, John and Tang, Jie and Zaremba, Wojciech},
  title   = {{OpenAI} gym},
  journal = {arXiv preprint arXiv:1606.01540},
  year    = {2016},
}

@InProceedings{li2010contextual,
  author       = {Li, Lihong and Chu, Wei and Langford, John and Schapire, Robert E},
  title        = {A contextual-bandit approach to personalized news article recommendation},
  booktitle    = {Proceedings of the 19th international conference on World wide web},
  year         = {2010},
  pages        = {661--670},
  organization = {ACM},
}

@Article{lei2012a,
  author    = {Lei, H and Nahum-Shani, I and Lynch, K and Oslin, D and Murphy, SA},
  title     = {A" SMART" design for building individualized treatment sequences},
  journal   = {Annual review of clinical psychology},
  year      = {2012},
  volume    = {8},
  pages     = {21--48},
  publisher = {Annual Reviews},
}

@Article{singh2002optimizing,
  author  = {Singh, Satinder and Litman, Diane and Kearns, Michael and Walker, Marilyn},
  title   = {Optimizing dialogue management with reinforcement learning: {E}xperiments with the {NJF}un system},
  journal = {Journal of Artificial Intelligence Research},
  year    = {2002},
  volume  = {16},
  pages   = {105--133},
}

@Article{williams1992simple,
  author    = {Williams, Ronald J},
  title     = {Simple statistical gradient-following algorithms for connectionist reinforcement learning},
  journal   = {Machine learning},
  year      = {1992},
  volume    = {8},
  number    = {3-4},
  pages     = {229--256},
  publisher = {Springer},
}

@PhdThesis{li2009unifying,
  author = {Li, Lihong},
  title  = {A unifying framework for computational reinforcement learning theory},
  school = {Rutgers, The State University of New Jersey},
  year   = {2009},
}

@Book{mohri2012foundations,
  title     = {Foundations of machine learning},
  publisher = {MIT press},
  year      = {2012},
  author    = {Mohri, Mehryar and Rostamizadeh, Afshin and Talwalkar, Ameet},
}

@InProceedings{vanseijen2015deeper,
  author    = {van Seijen, Harm and Sutton, Rich},
  title     = {A Deeper Look at Planning as Learning from Replay},
  booktitle = {Proceedings of the 32nd International Conference on Machine Learning},
  year      = {2015},
  pages     = {2314--2322},
}

@Article{bradtke1996linear,
  author    = {Bradtke, Steven J and Barto, Andrew G},
  title     = {Linear least-squares algorithms for temporal difference learning},
  journal   = {Machine learning},
  year      = {1996},
  volume    = {22},
  number    = {1-3},
  pages     = {33--57},
  publisher = {Springer},
}

@Article{lin1992self,
  author    = {Lin, Long-Ji},
  title     = {Self-improving reactive agents based on reinforcement learning, planning and teaching},
  journal   = {Machine learning},
  year      = {1992},
  volume    = {8},
  number    = {3-4},
  pages     = {293--321},
  publisher = {Springer},
}

@InProceedings{wang2016dueling,
  author    = {Wang, Ziyu and Schaul, Tom and Hessel, Matteo and Hasselt, Hado van and Lanctot, Marc and Freitas, Nando de},
  title     = {Dueling Network Architectures for Deep Reinforcement Learning},
  booktitle = {Proceedings of the 33rd International Conference on Machine Learning},
  year      = {2016},
  pages     = {1995--2003},
}
{sutton1996generalization,
	title={Generalization in reinforcement learning: {S}uccessful examples using sparse coarse coding},
	author={Sutton, Richard S},
	journal={Advances in Neural Information Processing Systems},
	pages={1038--1044},
	year={1996}
%	publisher={MORGAN KAUFMANN PUBLISHERS}
}

@PhdThesis{watkins1989learning,
  author = {Watkins, Christopher John Cornish Hellaby},
  title  = {Learning from delayed rewards},
  school = {University of Cambridge England},
  year   = {1989},
}

@Article{hoeffding1963probability,
  author    = {Hoeffding, Wassily},
  title     = {Probability inequalities for sums of bounded random variables},
  journal   = {Journal of the American statistical association},
  year      = {1963},
  volume    = {58},
  number    = {301},
  pages     = {13--30},
  publisher = {Taylor \& Francis Group},
}

@InProceedings{strehl2006pac,
  author       = {Strehl, Alexander L and Li, Lihong and Wiewiora, Eric and Langford, John and Littman, Michael L},
  title        = {{PAC} model-free reinforcement learning},
  booktitle    = {Proceedings of the 23rd international conference on Machine learning},
  year         = {2006},
  pages        = {881--888},
  organization = {ACM},
}

@Article{auer2007logarithmic,
  author    = {Auer, Peter and Ortner, Ronald},
  title     = {Logarithmic online regret bounds for undiscounted reinforcement learning},
  journal   = {Advances in Neural Information Processing Systems},
  year      = {2007},
  volume    = {19},
  pages     = {49},
  publisher = {MIT; 1998},
}

@Article{jaksch2010optimal,
  author  = {Jaksch, Thomas and Ortner, Ronald and Auer, Peter},
  title   = {Near-optimal regret bounds for reinforcement learning},
  journal = {Journal of Machine Learning Research},
  year    = {2010},
  volume  = {11},
  number  = {Apr},
  pages   = {1563--1600},
}

@PhdThesis{kakade2003sample,
  author = {Kakade, Sham Machandranath},
  title  = {On the sample complexity of reinforcement learning},
  school = {University of College London},
  year   = {2003},
}

@InProceedings{krishnamurthy2016pac,
  author    = {Krishnamurthy, Akshay and Agarwal, Alekh and Langford, John},
  title     = {{PAC} reinforcement learning with rich observations},
  booktitle = {Advances in Neural Information Processing Systems},
  year      = {2016},
  pages     = {1840--1848},
}


@InProceedings{jiang2017contextual,
  title = 	 {Contextual Decision Processes with low {B}ellman rank are {PAC}-Learnable},
  author = 	 {Nan Jiang and Akshay Krishnamurthy and Alekh Agarwal and John Langford and Robert E. Schapire},
  booktitle = 	 {International Conference on Machine Learning},
  year = 	 {2017}
}

@InProceedings{dann2015sample,
  author    = {Dann, Christoph and Brunskill, Emma},
  title     = {Sample complexity of episodic fixed-horizon reinforcement learning},
  booktitle = {Advances in Neural Information Processing Systems},
  year      = {2015},
  pages     = {2818--2826},
}

@Article{valiant1984theory,
  author    = {Valiant, Leslie G},
  title     = {A theory of the learnable},
  journal   = {Communications of the ACM},
  year      = {1984},
  volume    = {27},
  number    = {11},
  pages     = {1134--1142},
  publisher = {ACM},
}

@InProceedings{langford2008epoch,
  author    = {Langford, John and Zhang, Tong},
  title     = {The epoch-greedy algorithm for multi-armed bandits with side information},
  booktitle = {Advances in Neural Information Processing Systems},
  year      = {2008},
  pages     = {817--824},
}


@InProceedings{rosencrantz2004learning,
  author       = {Rosencrantz, Matthew and Gordon, Geoff and Thrun, Sebastian},
  title        = {Learning low dimensional predictive representations},
  booktitle    = {Proceedings of the twenty-first international conference on Machine learning},
  year         = {2004},
  pages        = {88},
  organization = {ACM},
}

@Article{kober2013reinforcement,
  author    = {Kober, Jens and Bagnell, J Andrew and Peters, Jan},
  title     = {Reinforcement learning in robotics: A survey},
  journal   = {The International Journal of Robotics Research},
  year      = {2013},
  pages     = {0278364913495721},
  publisher = {SAGE Publications},
}

@InProceedings{petrik2014raam,
  author    = {Petrik, Marek and Subramanian, Dharmashankar},
  title     = {{RAAM: The Benefits of Robustness in Approximating Aggregated MDPs in Reinforcement Learning}},
  booktitle = {Advances in Neural Information Processing Systems},
  year      = {2014},
  pages     = {1979--1987},
}

@Article{vanroy2006performance,
  author    = {Van Roy, Benjamin},
  title     = {Performance loss bounds for approximate value iteration with state aggregation},
  journal   = {Mathematics of Operations Research},
  year      = {2006},
  volume    = {31},
  number    = {2},
  pages     = {234--244},
  publisher = {INFORMS},
}

@InProceedings{kulesza2015low,
  author    = {Kulesza, Alex and Jiang, Nan and Singh, Satinder},
  title     = {{Low-Rank Spectral Learning with Weighted Loss Functions}},
  booktitle = {Proceedings of the 18th International Conference on Artificial Intelligence and Statistics},
  year      = {2015},
  pages     = {517--525},
}

@InCollection{riedmiller2005neural,
  author    = {Riedmiller, Martin},
  title     = {{Neural fitted Q iteration--first experiences with a data efficient neural reinforcement learning method}},
  booktitle = {Machine Learning: ECML 2005},
  publisher = {Springer},
  year      = {2005},
  pages     = {317--328},
}

@InProceedings{kobilarov2015sample,
  author    = {Kobilarov, Marin},
  title     = {{Sample Complexity Bounds for Iterative Stochastic Policy Optimization}},
  booktitle = {Advances in Neural Information Processing Systems},
  year      = {2015},
  pages     = {3096--3104},
}

@Article{bellman1956dynamic,
  author    = {Bellman, Richard},
  title     = {{Dynamic programming and Lagrange multipliers}},
  journal   = {Proceedings of the National Academy of Sciences},
  year      = {1956},
  volume    = {42},
  number    = {10},
  pages     = {767--769},
  publisher = {National Acad Sciences},
}

@Book{kumar2012customer,
  title     = {{Customer relationship management: Concept, strategy, and tools}},
  publisher = {Springer Science \& Business Media},
  year      = {2012},
  author    = {Kumar, Vineet and Reinartz, Werner},
}

@Article{murphy2003optimal,
  author    = {Murphy, Susan A},
  title     = {Optimal dynamic treatment regimes},
  journal   = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
  year      = {2003},
  volume    = {65},
  number    = {2},
  pages     = {331--355},
  publisher = {Wiley Online Library},
}

@InProceedings{hamilton2013modelling,
  author    = {Hamilton, William L and Fard, Mahdi M and Pineau, Joelle},
  title     = {Modelling sparse dynamical systems with compressed predictive state representations},
  booktitle = {Proceedings of the 30th International Conference on Machine Learning (ICML-13)},
  year      = {2013},
  pages     = {178--186},
}

@InProceedings{boots2010closing,
  author    = {Boots, Byron and Siddiqi, Sajid M and Gordon, Geoffrey J},
  title     = {Closing the learning-planning loop with predictive state representations},
  booktitle = {Proceedings of the 9th International Conference on Autonomous Agents and Multiagent Systems},
  year      = {2010},
  pages     = {1369--1370},
}

@InCollection{farahmand2008regularized,
  author    = {Farahmand, Amir-massoud and Ghavamzadeh, Mohammad and Szepesv{\'a}ri, Csaba and Mannor, Shie},
  title     = {{Regularized fitted Q-iteration: Application to planning}},
  booktitle = {Recent Advances in Reinforcement Learning},
  publisher = {Springer Berlin Heidelberg},
  year      = {2008},
  pages     = {55--68},
}

@InProceedings{farahmand2009regularized,
  author       = {Farahmand, Amir-massoud and Ghavamzadeh, Mohammad and Szepesv{\'a}ri, Csaba and Mannor, Shie},
  title        = {{Regularized fitted Q-iteration for planning in continuous-space Markovian decision problems}},
  booktitle    = {American Control Conference.},
  year         = {2009},
  pages        = {725--730},
  organization = {IEEE},
}

@InProceedings{szepesvari2005finite,
  author       = {Szepesv{\'a}ri, Csaba and Munos, R{\'e}mi},
  title        = {Finite time bounds for sampling based fitted value iteration},
  booktitle    = {Proceedings of the 22nd international conference on Machine learning},
  year         = {2005},
  pages        = {880--887},
  organization = {ACM},
}

@Article{antos2008learning,
  author    = {Antos, Andr{\'a}s and Szepesv{\'a}ri, Csaba and Munos, R{\'e}mi},
  title     = {Learning near-optimal policies with Bellman-residual minimization based fitted policy iteration and a single sample path},
  journal   = {Machine Learning},
  year      = {2008},
  volume    = {71},
  number    = {1},
  pages     = {89--129},
  publisher = {Springer},
}

@Article{lazaric2012finite,
  author    = {Lazaric, Alessandro and Ghavamzadeh, Mohammad and Munos, R{\'e}mi},
  title     = {Finite-sample analysis of least-squares policy iteration},
  journal   = {The Journal of Machine Learning Research},
  year      = {2012},
  volume    = {13},
  number    = {1},
  pages     = {3041--3074},
  publisher = {JMLR.org},
}

@Article{lagoudakis2003least,
  author    = {Lagoudakis, Michail G and Parr, Ronald},
  title     = {Least-squares policy iteration},
  journal   = {The Journal of Machine Learning Research},
  year      = {2003},
  volume    = {4},
  pages     = {1107--1149},
  publisher = {JMLR.org},
}

@Article{bertsekas2011approximate,
  author    = {Bertsekas, Dimitri P},
  title     = {Approximate policy iteration: A survey and some new methods},
  journal   = {Journal of Control Theory and Applications},
  year      = {2011},
  volume    = {9},
  number    = {3},
  pages     = {310--335},
  publisher = {Springer},
}

@InProceedings{gordon1995stable,
  author    = {Gordon, Geoffrey J},
  title     = {Stable function approximation in dynamic programming},
  booktitle = {Proceedings of the twelfth international conference on machine learning},
  year      = {1995},
  pages     = {261--268},
}

@Book{bertsekas1996neuro,
  title     = {Neuro-Dynamic Programming},
  publisher = {Athena Scientific, Belmont, MA},
  year      = {1996},
  author    = {Bertsekas, Dimitri P and Tsitsiklis, John N},
}

@Article{bellman1959functional,
  author    = {Bellman, Richard and Dreyfus, Stuart},
  title     = {Functional approximations and dynamic programming},
  journal   = {Mathematical Tables and Other Aids to Computation},
  year      = {1959},
  volume    = {13},
  number    = {68},
  pages     = {247--251},
  publisher = {JSTOR},
}

@Article{munos2007performance,
  author    = {Munos, R{\'e}mi},
  title     = {Performance bounds in l\_p-norm for approximate value iteration},
  journal   = {SIAM journal on control and optimization},
  year      = {2007},
  volume    = {46},
  number    = {2},
  pages     = {541--561},
  publisher = {SIAM},
}

@Article{pires2016policy,
  author  = {Pires, Bernardo {\'A}vila and Szepesv{\'a}ri, Csaba},
  title   = {Policy Error Bounds for Model-Based Reinforcement Learning with Factored Linear Models},
  journal = {arXiv preprint arXiv:1602.06346},
  year    = {2016},
}

@Article{ernst2005tree,
  author    = {Ernst, Damien and Geurts, Pierre and Wehenkel, Louis},
  title     = {Tree-based batch mode reinforcement learning},
  journal   = {Journal of Machine Learning Research},
  year      = {2005},
  volume    = {6},
  pages     = {503--556},
  publisher = {Microtome Publishing},
}

@Article{mnih2015human,
  author    = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  title     = {Human-level control through deep reinforcement learning},
  journal   = {Nature},
  year      = {2015},
  volume    = {518},
  number    = {7540},
  pages     = {529--533},
  publisher = {Nature Publishing Group},
}

@Article{silver2016mastering,
  author    = {Silver, David and Huang, Aja and Maddison, Chris J and Guez, Arthur and Sifre, Laurent and van den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and others},
  title     = {Mastering the game of Go with deep neural networks and tree search},
  journal   = {Nature},
  year      = {2016},
  volume    = {529},
  number    = {7587},
  pages     = {484--489},
  publisher = {Nature Publishing Group},
}

@InProceedings{jiang2016doubly,
  author    = {Nan Jiang and Lihong Li},
  title     = {{Doubly Robust Off-policy Value Evaluation for Reinforcement Learning}},
  booktitle = {Proceedings of The 33rd International Conference on Machine Learning},
  year      = {2016},
  volume    = {48},
  pages     = {652--661},
}

@InProceedings{thomas2016data,
  author    = {Thomas, Philip and Brunskill, Emma},
  title     = {{Data-Efficient Off-Policy Policy Evaluation for Reinforcement Learning}},
  booktitle = {Proceedings of the 33rd International Conference on Machine Learning},
  year      = {2016},
}

@InProceedings{li2015minimax,
  author    = {Li, Lihong and Munos, R{\'e}mi and Szepesv{\'a}ri, Csaba},
  title     = {Toward Minimax Off-policy Value Estimation},
  booktitle = {Proceedings of the 18th International Conference on Artificial Intelligence and Statistics},
  year      = {2015},
}

@InProceedings{kakade2002approximately,
  author    = {Kakade, Sham and Langford, John},
  title     = {{Approximately Optimal Approximate Reinforcement Learning}},
  booktitle = {Proceedings of the 19th International Conference on Machine Learning},
  year      = {2002},
  volume    = {2},
  pages     = {267--274},
}

@InProceedings{jiang2015abstraction,
  author    = {Jiang, Nan and Kulesza, Alex and Singh, Satinder},
  title     = {{Abstraction Selection in Model-based Reinforcement Learning}},
  booktitle = {Proceedings of the 32nd International Conference on Machine Learning},
  year      = {2015},
  pages     = {179--188},
}

@InProceedings{thomas2015high,
  author    = {Thomas, Philip and Theocharous, Georgios and Ghavamzadeh, Mohammad},
  title     = {{High Confidence Off-Policy Evaluation}},
  booktitle = {Proceedings of the 29th AAAI Conference on Artificial Intelligence},
  year      = {2015},
}

@InProceedings{dudik2011doubly,
  author    = {Dud{\'\i}k, Miroslav and Langford, John and Li, Lihong},
  title     = {Doubly {R}obust {P}olicy {E}valuation and {L}earning},
  booktitle = {Proceedings of the 28th International Conference on Machine Learning},
  year      = {2011},
  pages     = {1097--1104},
}

@InProceedings{thomas2015higha,
  author    = {Thomas, Philip and Theocharous, Georgios and Ghavamzadeh, Mohammad},
  title     = {{High Confidence Policy Improvement}},
  booktitle = {Proceedings of the 32nd International Conference on Machine Learning},
  year      = {2015},
  pages     = {2380--2388},
}

@InProceedings{kearns2000bias,
  author       = {Kearns, Michael J and Singh, Satinder P},
  title        = {{Bias-Variance Error Bounds for Temporal Difference Updates}},
  booktitle    = {Proceedings of the Thirteenth Annual Conference on Computational Learning Theory},
  year         = {2000},
  pages        = {142--147},
  organization = {Morgan Kaufmann Publishers Inc.},
}

@InProceedings{sutton2014new,
  author    = {Sutton, Rich and Mahmood, Ashique R and Precup, Doina and Hasselt, Hado V},
  title     = {A new {Q}($\lambda$) with interim forward view and {M}onte {C}arlo equivalence},
  booktitle = {Proceedings of the 31st International Conference on Machine Learning},
  year      = {2014},
  pages     = {568--576},
}

@Article{singh1996reinforcement,
  author    = {Singh, Satinder P and Sutton, Richard S},
  title     = {Reinforcement learning with replacing eligibility traces},
  journal   = {Machine learning},
  year      = {1996},
  volume    = {22},
  number    = {1-3},
  pages     = {123--158},
  publisher = {Springer},
}

@InCollection{kocsis2006bandit,
  author    = {Kocsis, Levente and Szepesv{\'a}ri, Csaba},
  title     = {Bandit based monte-carlo planning},
  booktitle = {Machine Learning: ECML 2006},
  publisher = {Springer Berlin Heidelberg},
  year      = {2006},
  pages     = {282--293},
}

@Misc{hettich1999uci,
  author       = {Hettich, S and Bay, S D},
  title        = {{The UCI KDD Archive}},
  howpublished = {\url{http://kdd.ics.uci.edu}},
  year         = {1999},
}

@InProceedings{precup2001policy,
  author    = {Doina Precup and Richard S Sutton and Sanjoy Dasgupta},
  title     = {{Off-Policy Temporal-Difference Learning with Funtion Approximation}},
  booktitle = {Proceedings of the 18th International Conference on Machine Learning},
  year      = {2001},
  pages     = {417--424},
}

@InProceedings{precup2000eligibility,
  author    = {Doina Precup and Richard S Sutton and Satinder P Singh},
  title     = {{Eligibility Traces for Off-Policy Policy Evaluation}},
  booktitle = {Proceedings of the 17th International Conference on Machine Learning},
  year      = {2000},
  pages     = {759--766},
}

@Book{sutton1998reinforcement,
  title     = {Reinforcement Learning: An Introduction},
  publisher = {MIT Press},
  year      = {1998},
  author    = {Richard S Sutton and Andrew G Barto},
  address   = {Cambridge, MA},
  month     = {March},
  isbn      = {0-262-19398-1},
}

@Article{murphy2001marginal,
  author  = {Susan A. Murphy and Mark van der Laan and James M. Robins},
  title   = {{Marginal Mean Models for Dynamic Regimes}},
  journal = {Journal of the American Statistical Association},
  year    = {2001},
  volume  = {96},
  number  = {456},
  pages   = {1410--1423},
}

@InProceedings{li2011unbiased,
  author    = {Lihong Li and Wei Chu and John Langford and Xuanhui Wang},
  title     = {{Unbiased Offline Evaluation of Contextual-bandit-based News Article Recommendation Algorithms}},
  booktitle = {Proceedings of the 4th International Conference on Web Search and Data Mining},
  year      = {2011},
  pages     = {297--306},
}

@Article{bottou2013counterfactual,
  author  = {L\'{e}on Bottou and Jonas Peters and Joaquin Qui{\~n}onero-Candela and Denis Xavier Charles and D. Max Chickering and Elon Portugaly and Dipankar Ray and Patrice Simard and Ed Snelson},
  title   = {{Counterfactual Reasoning and Learning Systems: The Example of Computational Advertising}},
  journal = {Journal of Machine Learning Research},
  year    = {2013},
  volume  = {14},
  pages   = {3207--3260},
}

@InProceedings{sutton1998intra,
  author    = {Richard S Sutton and Doina Precup and Satinder P Singh},
  title     = {{Intra-option Learning about Temporally Abstract Actions}},
  booktitle = {Proceedings of the 15th International Conference on Machine Learning},
  year      = {1998},
  pages     = {556--564},
}

@PhdThesis{precup2000temporal,
  author = {Precup, Doina},
  title  = {Temporal abstraction in reinforcement learning},
  school = {University of Massachusetts Amherst},
  year   = {2000},
}

@PhdThesis{thomas2015safe,
  author = {Thomas, Philip},
  title  = {Safe Reinforcement Learning},
  school = {University of Massachusetts Amherst},
  year   = {2015},
}

@InProceedings{gruenewaelder2012modelling,
  author    = {Gr{\"u}new{\"a}lder, S and Lever, G and Baldassarre, L and Pontil, M and Gretton, A},
  title     = {{Modelling transition dynamics in MDPs with RKHS embeddings}},
  booktitle = {Proceedings of the 29th International Conference on Machine Learning},
  year      = {2012},
  pages     = {535--542},
}

@InProceedings{jong2007model,
  author    = {Jong, Nicholas K and Stone, Peter},
  title     = {Model-based function approximation in reinforcement learning},
  booktitle = {Proceedings of the 6th International Conference on Autonomous Agents and Multiagent Systems},
  year      = {2007},
  pages     = {95},
}

@Article{dann2014policy,
  author  = {Dann, Christoph and Neumann, Gerhard and Peters, Jan},
  title   = {Policy evaluation with temporal differences: {A} survey and comparison},
  journal = {The Journal of Machine Learning Research},
  year    = {2014},
  volume  = {15},
  number  = {1},
  pages   = {809--883},
}

@Article{fonteneau2013batch,
  author  = {Raphael Fonteneau and Susan A. Murphy and Louis Wehenkel and Damien Ernst},
  title   = {Batch Mode Reinforcement Learning based on the Synthesis of Artificial Trajectories},
  journal = {Annals of Operations Research},
  year    = {2013},
  volume  = {208},
  number  = {1},
  pages   = {383--416},
}

@Article{rotnitzky1995semiparametric,
  author  = {Andrea Rotnitzky and James M. Robins},
  title   = {Semiparametric Regression Estimation in the Presence of Dependent Censoring},
  journal = {Biometrika},
  year    = {1995},
  volume  = {82},
  number  = {4},
  pages   = {805--820},
}

@InProceedings{pirotta2013safe,
  author    = {Matteo Pirotta and Marcello Restelli and Alessio Pecorino and Daniele Calandriello},
  title     = {Safe Policy Iteration},
  booktitle = {Proceedings of the 30th International Conference on Machine Learning},
  year      = {2013},
  number    = {3},
  pages     = {307--317},
}

@Book{pearl2009causality,
  title     = {Causality: Models, Reasoning, and Inference},
  publisher = {Cambridge University Press},
  year      = {2009},
  author    = {Judea Pearl},
  edition   = {2nd},
  isbn      = {052189560X},
}

@Article{holland1986statistics,
  author  = {Paul W. Holland},
  title   = {Statistics and Causal Inference},
  journal = {Journal of the American Statistical Association},
  year    = {1986},
  volume  = {81},
  number  = {6},
  pages   = {945--960},
}

@Unpublished{sutton2015emphatic,
  author = {Richard S Sutton and Ashique Rupam Mahmood and Martha White},
  title  = {An Emphatic Approach to the Problem of Off-policy Temporal-Difference Learning},
  note   = {CoRR abs/1503.04269},
  year   = {2015},
}

@Article{hirano2003efficient,
  author  = {Hirano, Keisuke and Imbens, Guido W. and Ridder, Geert},
  title   = {Efficient Estimation of Average Treatment Effects using the Estimated Propensity Score},
  journal = {Econometrica},
  year    = {2003},
  volume  = {71},
  number  = {4},
  pages   = {1161--1189},
}

@InProceedings{pednault2002sequential,
  author     = {Edwin P. D. Pednault and Naoki Abe and Bianca Zadrozny},
  title      = {Sequential Cost-Sensitive Decision-Making with Reinforcement Learning},
  booktitle  = {KDD},
  year       = {2002},
  pages      = {259--268},
  booktitle1 = {Proceedings of the 8th International Conference on Knowledge Discovery and Data Mining},
}

@PhdThesis{jr2010theory,
  author = {Moore Jr, Terrence Joseph},
  title  = {A theory of Cramer-Rao bounds for constrained parametric models},
  school = {University of Maryland, College Park},
  year   = {2010},
}

@PhdThesis{marivate2015improved,
  author  = {Vukosi N. Marivate},
  title   = {Improved Empirical Methods in Reinforcement-Learning Evaluation},
  school  = {Rutgers University},
  year    = {2015},
  address = {New Brunswick, NJ},
}

@InProceedings{marivate2014quantifying,
  author    = {Marivate, Vukosi Ntsakisi and Chemali, Jessica and Brunskill, Emma and Littman, Michael},
  title     = {Quantifying uncertainty in batch personalized sequential decision making},
  booktitle = {Workshops at the 28th AAAI Conference on Artificial Intelligence},
  year      = {2014},
}

@Article{jiang2015doubly,
  author  = {Jiang, Nan and Li, Lihong},
  title   = {Doubly Robust Off-policy Evaluation for Reinforcement Learning},
  journal = {arXiv preprint arXiv:1511.03722},
  year    = {2015},
}

@InProceedings{singh2004predictive,
  author       = {Singh, Satinder and James, Michael R and Rudary, Matthew R},
  title        = {{Predictive state representations: A new theory for modeling dynamical systems}},
  booktitle    = {Proceedings of the 20th Conference on Uncertainty in Artificial Intelligence},
  year         = {2004},
  pages        = {512--519},
  organization = {AUAI Press},
}

@InProceedings{doshi-velez2009infinite,
  author    = {Doshi-Velez, Finale},
  title     = {{The Infinite Partially observable Markov decision process}},
  booktitle = {Advances in Neural Information Processing Systems},
  year      = {2009},
  pages     = {477--485},
}

@Misc{li2015recurrent,
  author = {Xiujun Li and Lihong Li and Jianfeng Gao and Xiaodong He and Jianshu Chen and Li Deng and Ji He},
  title  = {Recurrent Reinforcement Learning: A Hybrid Approach},
  year   = {2015},
  note   = {arXiv:1509.03044},
}

@InProceedings{asmuth2011approaching,
  author    = {Asmuth, John and Littman, Michael L},
  title     = {Approaching {B}ayes-optimalilty using {M}onte-{C}arlo tree search},
  booktitle = {Proceedings of the 21st International Conference on Automatated Planning and Scheduling},
  year      = {2011},
}

@Article{bagnell2001solving,
  author    = {Bagnell, J Andrew and Ng, Andrew Y and Schneider, Jeff G},
  title     = {Solving uncertain {M}arkov decision processes},
  year      = {2001},
  publisher = {Carnegie Mellon University},
}

@Article{bertuccelli2012robust,
  author    = {Bertuccelli, Luca F and Wu, Albert and How, Jonathan P},
  title     = {Robust Adaptive Markov Decision Processes: Planning with Model Uncertainty},
  journal   = {Control Systems, IEEE},
  year      = {2012},
  volume    = {32},
  number    = {5},
  pages     = {96--109},
  publisher = {IEEE},
}

@InCollection{el-yaniv2007transductive,
  author    = {El-Yaniv, Ran and Pechyony, Dmitry},
  title     = {{T}ransductive rademacher complexity and its applications},
  booktitle = {Learning Theory},
  publisher = {Springer},
  year      = {2007},
  pages     = {157--171},
}

@Article{even-dar2009online,
  author    = {Even-Dar, Eyal and Kakade, Sham M and Mansour, Yishay},
  title     = {Online {M}arkov decision processes},
  journal   = {Mathematics of Operations Research},
  year      = {2009},
  volume    = {34},
  number    = {3},
  pages     = {726--736},
  publisher = {INFORMS},
}

@InProceedings{guez2012efficient,
  author    = {Guez, Arthur and Silver, David and Dayan, Peter},
  title     = {Efficient {B}ayes-{A}daptive {R}einforcement {L}earning using {S}ample-{B}ased {S}earch},
  booktitle = {Advances in Neural Information Processing Systems},
  year      = {2012},
  pages     = {1034--1042},
}

@Article{browne2012survey,
  author  = {Browne, Cameron B and Powley, Edward and Whitehouse, Daniel and Lucas, Simon M and Cowling, Peter I and Rohlfshagen, Philipp and Tavener, Stephen and Perez, Diego and Samothrakis, Spyridon and Colton, Simon},
  title   = {A survey of {M}onte {C}arlo tree search methods},
  journal = {IEEE Transactions on Computational Intelligence and AI in Games},
  year    = {2012},
  volume  = {4},
  number  = {1},
  pages   = {1--43},
}

@Book{montenegro2006mathematical,
  title     = {Mathematical aspects of mixing times in {M}arkov chains},
  publisher = {Now Publishers Inc},
  year      = {2006},
  author    = {Montenegro, Ravi R and Tetali, Prasad},
}
{ng2000pegasus,
  title =	 {{PEGASUS}: {A} policy search method for large {MDP}s and
                  {POMDP}s},
  author =	 {Ng, Andrew Y and Jordan, Michael},
  booktitle =	 {Proceedings of the16th Conference on
                  Uncertainty in Artificial Intelligence},
  pages =	 {406--415},
  year =	 2000
%  organization = {Morgan Kaufmann Publishers Inc.}
}

@Article{nilim2005robust,
  author  = {Nilim, Arnab and El Ghaoui, Laurent},
  title   = {Robust control of {M}arkov decision processes with uncertain transition matrices},
  journal = {Operations Research},
  year    = {2005},
  volume  = {53},
  number  = {5},
  pages   = {780--798},
}

@InProceedings{silver2010montea,
  author    = {Silver, David and Veness, Joel},
  title     = {{M}onte-{C}arlo planning in large {POMDP}s},
  booktitle = {Advances in Neural Information Processing Systems},
  year      = {2010},
  pages     = {2164--2172},
}

@InProceedings{smith2004heuristic,
  author    = {Smith, Trey and Simmons, Reid},
  title     = {Heuristic search value iteration for {POMDP}s},
  booktitle = {Proceedings of the 20th Conference on Uncertainty in Artificial Intelligence},
  year      = {2004},
  pages     = {520--527},
}

@Article{ross2011bayesian,
  author    = {Ross, St{\'e}phane and Pineau, Joelle and Chaib-draa, Brahim and Kreitmann, Pierre},
  title     = {A {B}ayesian approach for learning and planning in partially observable {M}arkov decision processes},
  journal   = {The Journal of Machine Learning Research},
  year      = {2011},
  volume    = {12},
  pages     = {1729--1770},
  publisher = {JMLR.org},
}

@InProceedings{bjarnason2009lower,
  author    = {Bjarnason, Ronald and Fern, Alan and Tadepalli, Prasad},
  title     = {Lower bounding {K}londike solitaire with {M}onte-{C}arlo planning},
  booktitle = {Proceedings of International Conference on Automated Planning and Scheduling},
  year      = {2009},
  pages     = {26--33},
}

@InProceedings{zhu2009human,
  author    = {Zhu, Xiaojin and Gibson, Bryan R and Rogers, Timothy T},
  title     = {Human {R}ademacher complexity},
  booktitle = {Advances in Neural Information Processing Systems},
  year      = {2009},
  pages     = {2322--2330},
}

@Manual{balcan2011cs,
  title        = {{CS} 8803 - {M}achine {L}earning {T}heory: {L}ecture {N}otes},
  author       = {Balcan, Maria-Florina},
  organization = {{G}eorgia {I}nstitute of {T}echnology},
  year         = {2011},
  note         = {\url{http://www.cs.cmu.edu/~ninamf/ML11/lect1115.pdf}},
}

@Manual{kakade2011hoeffding,
  title = {{Hoeffding, Chernoff, Bennet, and Bernstein Bounds}},
  author = {Kakade, Sham},
  year = {2011},
  note = {\url{http://stat.wharton.upenn.edu/~skakade/courses/stat928/lectures/lecture06.pdf}},
}

@InProceedings{petrik2009biasing,
  author    = {Petrik, Marek and Scherrer, Bruno},
  title     = {Biasing approximate dynamic programming with a lower discount factor},
  booktitle = {Advances in Neural Information Processing Systems},
  year      = {2009},
  pages     = {1265--1272},
}

@Article{vapnik1999overview,
  author    = {Vapnik, Vladimir N},
  title     = {An overview of statistical learning theory},
  journal   = {Neural Networks, IEEE Transactions on},
  year      = {1999},
  volume    = {10},
  number    = {5},
  pages     = {988--999},
  publisher = {IEEE},
}

@Article{baxter2001infinite,
  author  = {Baxter, Jonathan and Bartlett, Peter L},
  title   = {{Infinite-Horizon Policy-Gradient Estimation}},
  journal = {Journal of Artificial Intelligence Research},
  year    = {2001},
  volume  = {15},
  pages   = {319--350},
}

@Article{amin2017repeated,
  author        = {Amin, Kareem and Jiang, Nan and Singh, Satinder},
  title         = {{Repeated Inverse Reinforcement Learning for AI Safety}},
  journal       = {arXiv preprint arXiv:1705.05427},
  year          = {2017},
  __markedentry = {[najiang:]},
}

@Article{bostrom2003ethical,
  author        = {Bostrom, Nick},
  title         = {Ethical issues in advanced artificial intelligence},
  journal       = {Science Fiction and Philosophy: From Time Travel to Superintelligence},
  year          = {2003},
  pages         = {277--284},
  __markedentry = {[najiang:]},
}

@InProceedings{walsh2010generalizing,
  author        = {Walsh, Thomas J and Subramanian, Kaushik and Littman, Michael L and Diuk, Carlos},
  title         = {Generalizing apprenticeship learning across hypothesis classes},
  booktitle     = {Proceedings of the 27th International Conference on Machine Learning (ICML-10)},
  year          = {2010},
  pages         = {1119--1126},
  __markedentry = {[najiang:]},
}

@Article{li2011knows,
  author        = {Li, Lihong and Littman, Michael L and Walsh, Thomas J and Strehl, Alexander L},
  title         = {Knows what it knows: a framework for self-aware learning},
  journal       = {Machine learning},
  year          = {2011},
  volume        = {82},
  number        = {3},
  pages         = {399--443},
  __markedentry = {[najiang:]},
  publisher     = {Springer},
}

@InProceedings{dani2008stochastic,
  author        = {Dani, Varsha and Hayes, Thomas P and Kakade, Sham M},
  title         = {Stochastic Linear Optimization under Bandit Feedback.},
  booktitle     = {COLT},
  year          = {2008},
  pages         = {355--366},
  __markedentry = {[najiang:]},
}

@InProceedings{abbasi-yadkori2012online,
  author        = {Abbasi-Yadkori, Yasin and Pal, David and Szepesvari, Csaba},
  title         = {Online-to-Confidence-Set Conversions and Application to Sparse Stochastic Bandits.},
  booktitle     = {AISTATS},
  year          = {2012},
  volume        = {22},
  pages         = {1--9},
  __markedentry = {[najiang:]},
}

@Article{mannor2004sample,
  author        = {Mannor, Shie and Tsitsiklis, John N},
  title         = {The sample complexity of exploration in the multi-armed bandit problem},
  journal       = {Journal of Machine Learning Research},
  year          = {2004},
  volume        = {5},
  number        = {Jun},
  pages         = {623--648},
  __markedentry = {[najiang:]},
}

@Article{auer2002using,
  author        = {Auer, Peter},
  title         = {Using confidence bounds for exploitation-exploration trade-offs},
  journal       = {Journal of Machine Learning Research},
  year          = {2002},
  volume        = {3},
  number        = {Nov},
  pages         = {397--422},
  __markedentry = {[najiang:]},
}

@InProceedings{neu2014online,
  author        = {Neu, Gergely and Valko, Michal},
  title         = {Online combinatorial optimization with stochastic decision sets and adversarial losses},
  booktitle     = {Advances in Neural Information Processing Systems},
  year          = {2014},
  pages         = {2780--2788},
  __markedentry = {[najiang:]},
}

@Article{kleinberg2010regret,
  author        = {Kleinberg, Robert and Niculescu-Mizil, Alexandru and Sharma, Yogeshwer},
  title         = {Regret bounds for sleeping experts and bandits},
  journal       = {Machine learning},
  year          = {2010},
  volume        = {80},
  number        = {2-3},
  pages         = {245--272},
  __markedentry = {[najiang:]},
  publisher     = {Springer},
}

@Article{blum2007external,
  author        = {Blum, Avrim and Mansour, Yishay},
  title         = {From external to internal regret},
  journal       = {Journal of Machine Learning Research},
  year          = {2007},
  volume        = {8},
  number        = {Jun},
  pages         = {1307--1324},
  __markedentry = {[najiang:]},
}

@InProceedings{freund1997using,
  author        = {Freund, Yoav and Schapire, Robert E and Singer, Yoram and Warmuth, Manfred K},
  title         = {Using and combining predictors that specialize},
  booktitle     = {Proceedings of the 29th Annual ACM Symposium on Theory of computing},
  year          = {1997},
  pages         = {334--343},
  organization  = {ACM},
  __markedentry = {[najiang:]},
}

@InProceedings{kanade2009sleeping,
  author        = {Kanade, Varun and McMahan, H Brendan and Bryan, Brent},
  title         = {Sleeping Experts and Bandits with Stochastic Action Availability and Adversarial Rewards},
  booktitle     = {AISTATS},
  year          = {2009},
  pages         = {272--279},
  __markedentry = {[najiang:]},
}

@Book{groetschel2012geometric,
  title         = {Geometric algorithms and combinatorial optimization},
  publisher     = {Springer Science \& Business Media},
  year          = {2012},
  author        = {Gr{\"o}tschel, Martin and Lov{\'a}sz, L{\'a}szl{\'o} and Schrijver, Alexander},
  volume        = {2},
  __markedentry = {[najiang:]},
}

@InProceedings{hadfield-menell2016cooperative,
  author        = {Hadfield-Menell, Dylan and Russell, Stuart J and Abbeel, Pieter and Dragan, Anca},
  title         = {Cooperative inverse reinforcement learning},
  booktitle     = {Advances in Neural Information Processing Systems},
  year          = {2016},
  pages         = {3909--3917},
  __markedentry = {[najiang:]},
}

@Article{russell2015research,
  author        = {Russell, Stuart and Dewey, Daniel and Tegmark, Max},
  title         = {Research priorities for robust and beneficial artificial intelligence},
  journal       = {AI Magazine},
  year          = {2015},
  volume        = {36},
  number        = {4},
  pages         = {105--114},
  __markedentry = {[najiang:]},
}

@Article{amodei2016concrete,
  author        = {Amodei, Dario and Olah, Chris and Steinhardt, Jacob and Christiano, Paul and Schulman, John and Man{\'e}, Dan},
  title         = {Concrete problems in {AI} safety},
  journal       = {arXiv preprint arXiv:1606.06565},
  year          = {2016},
  __markedentry = {[najiang:]},
}

@Article{todd1982minimum,
  author        = {Todd, Michael J},
  title         = {On minimum volume ellipsoids containing part of a given ellipsoid},
  journal       = {Mathematics of Operations Research},
  year          = {1982},
  volume        = {7},
  number        = {2},
  pages         = {253--261},
  __markedentry = {[najiang:]},
  publisher     = {INFORMS},
}

@InProceedings{auer1995gambling,
  author        = {Auer, Peter and Cesa-Bianchi, Nicolo and Freund, Yoav and Schapire, Robert E},
  title         = {Gambling in a rigged casino: The adversarial multi-armed bandit problem},
  booktitle     = {Foundations of Computer Science, 1995. Proceedings., 36th Annual Symposium on},
  year          = {1995},
  pages         = {322--331},
  organization  = {IEEE},
  __markedentry = {[najiang:]},
}

@article{auer2002nonstochastic,
  title={The nonstochastic multiarmed bandit problem},
  author={Auer, Peter and Cesa-Bianchi, Nicolo and Freund, Yoav and Schapire, Robert E},
  journal={SIAM journal on computing},
  volume={32},
  number={1},
  pages={48--77},
  year={2002},
  publisher={SIAM}
}

@Article{bartlett2008high,
  author        = {Bartlett, Peter L and Dani, Varsha and Hayes, Thomas and Kakade, Sham and Rakhlin, Alexander and Tewari, Ambuj},
  title         = {High-probability regret bounds for bandit online linear optimization},
  year          = {2008},
  pages         = {335-342},
  __markedentry = {[najiang:]},
  booktitle     = {Proceedings of the 21st Annual Conference on Learning Theory},
}

@InProceedings{abernethy2008competing,
  author        = {Abernethy, Jacob and Hazan, Elad and Rakhlin, Alexander},
  title         = {Competing in the Dark: An Efficient Algorithm for Bandit Linear Optimization},
  booktitle     = {Conference on Learning Theory},
  year          = {2008},
  pages         = {263--274},
  __markedentry = {[najiang:]},
}

@InProceedings{dani2007price,
  author        = {Dani, Varsha and Kakade, Sham M and Hayes, Thomas P},
  title         = {The price of bandit information for online optimization},
  booktitle     = {Advances in Neural Information Processing Systems},
  year          = {2007},
  pages         = {345--352},
  __markedentry = {[najiang:]},
}


@InProceedings{hsu2015mixing,
  author        = {Hsu, Daniel J and Kontorovich, Aryeh and Szepesv{\'a}ri, Csaba},
  title         = {Mixing time estimation in reversible Markov chains from a single sample path},
  booktitle     = {Advances in Neural Information Processing Systems},
  year          = {2015},
  pages         = {1459--1467},
  __markedentry = {[najiang:]},
}

@Manual{odonnell201115,
  title         = {15-859({E}) -- linear and semidefinite programming: lecture notes},
  author        = {Ryan O'Donnell},
  organization  = {{Carnegie Mellon University}},
  year          = {2011},
  note          = {\url{https://www.cs.cmu.edu/afs/cs.cmu.edu/academic/class/15859-f11/www/notes/lecture08.pdf}},
  __markedentry = {[najiang:]},
}

@InProceedings{jiang2015dependence,
  author        = {Jiang, Nan and Kulesza, Alex and Singh, Satinder and Lewis, Richard},
  title         = {The Dependence of Effective Planning Horizon on Model Accuracy},
  booktitle     = {Proceedings of the 2015 International Conference on Autonomous Agents and Multiagent Systems},
  year          = {2015},
  pages         = {1181--1189},
  __markedentry = {[najiang:]},
}


@Article{amin2016towards,
  author        = {Amin, Kareem and Singh, Satinder},
  title         = {Towards Resolving Unidentifiability in Inverse Reinforcement Learning},
  journal       = {arXiv preprint arXiv:1601.06569},
  year          = {2016},
  __markedentry = {[najiang:]},
}

@Article{lovasz1999hit,
  author        = {Lov{\'a}sz, L{\'a}szl{\'o}},
  title         = {Hit-and-run mixes fast},
  journal       = {Mathematical Programming},
  year          = {1999},
  volume        = {86},
  number        = {3},
  pages         = {443--461},
  __markedentry = {[najiang:]},
  publisher     = {Springer},
}

@Article{lovasz2006simulated,
  author        = {Lov{\'a}sz, L{\'a}szl{\'o} and Vempala, Santosh},
  title         = {Simulated annealing in convex bodies and an O*(n4) volume algorithm},
  journal       = {Journal of Computer and System Sciences},
  year          = {2006},
  volume        = {72},
  number        = {2},
  pages         = {392--417},
  __markedentry = {[najiang:]},
  publisher     = {Elsevier},
}

@Article{cousinspractical,
  author        = {Cousins, Ben and Vempala, Santosh},
  title         = {A Practical Volume Algorithm},
  __markedentry = {[najiang:]},
}

@InProceedings{coates2008learning,
  author        = {Coates, Adam and Abbeel, Pieter and Ng, Andrew Y},
  title         = {Learning for control from multiple demonstrations},
  booktitle     = {Proceedings of the 25th international conference on Machine learning},
  year          = {2008},
  pages         = {144--151},
  organization  = {ACM},
  __markedentry = {[najiang:]},
}

@InProceedings{ziebart2008maximum,
  author        = {Ziebart, Brian D and Maas, Andrew L and Bagnell, J Andrew and Dey, Anind K},
  title         = {Maximum Entropy Inverse Reinforcement Learning},
  booktitle     = {AAAI},
  year          = {2008},
  pages         = {1433--1438},
  __markedentry = {[najiang:]},
}

@Article{ramachandran2007bayesian,
  author        = {Ramachandran, Deepak and Amir, Eyal},
  title         = {Bayesian inverse reinforcement learning},
  journal       = {Urbana},
  year          = {2007},
  volume        = {51},
  pages         = {61801},
  __markedentry = {[najiang:]},
}

@InProceedings{syed2007game,
  author        = {Syed, Umar and Schapire, Robert E},
  title         = {A game-theoretic approach to apprenticeship learning},
  booktitle     = {Advances in Neural Information Processing Systems},
  year          = {2007},
  pages         = {1449--1456},
  __markedentry = {[najiang:]},
}

@InProceedings{guillory2010interactive,
  author        = {Guillory, Andrew and Bilmes, Jeff},
  title         = {Interactive submodular set cover},
  booktitle     = {Proceedings of the International Conference on Machine Learning},
  year          = {2010},
  __markedentry = {[najiang:]},
}

@InProceedings{golovin2010adaptive,
  author        = {Golovin, Daniel and Krause, Andreas},
  title         = {Adaptive Submodularity: A New Approach to Active Learning and Stochastic Optimization},
  booktitle     = {COLT},
  year          = {2010},
  pages         = {333--345},
  __markedentry = {[najiang:]},
}

@InProceedings{ratliff2006maximum,
  author        = {Ratliff, Nathan D and Bagnell, J Andrew and Zinkevich, Martin A},
  title         = {Maximum margin planning},
  booktitle     = {Proceedings of the 23rd International Conference on Machine Learning},
  year          = {2006},
  pages         = {729--736},
  organization  = {ACM},
  __markedentry = {[najiang:]},
}

@InProceedings{regan2010robust,
  author        = {Regan, Kevin and Boutilier, Craig},
  title         = {Robust Policy Computation in Reward-Uncertain MDPs Using Nondominated Policies},
  booktitle     = {AAAI},
  year          = {2010},
  __markedentry = {[najiang:]},
}

@InProceedings{smart2002effective,
  author        = {Smart, William D and Kaelbling, Leslie Pack},
  title         = {Effective reinforcement learning for mobile robots},
  booktitle     = {Robotics and Automation, 2002. Proceedings. ICRA'02. IEEE International Conference on},
  year          = {2002},
  volume        = {4},
  pages         = {3404--3410},
  organization  = {IEEE},
  __markedentry = {[najiang:]},
}

@Article{abbeel2007application,
  author        = {Abbeel, Pieter and Coates, Adam and Quigley, Morgan and Ng, Andrew Y},
  title         = {An application of reinforcement learning to aerobatic helicopter flight},
  journal       = {Advances in Neural Information Processing Systems},
  year          = {2007},
  volume        = {19},
  pages         = {1},
  __markedentry = {[najiang:]},
  publisher     = {MIT; 1998},
}

@Article{coates2009apprenticeship,
  author        = {Coates, Adam and Abbeel, Pieter and Ng, Andrew Y},
  title         = {Apprenticeship learning for helicopter control},
  journal       = {Communications of the ACM},
  year          = {2009},
  volume        = {52},
  number        = {7},
  pages         = {97--105},
  __markedentry = {[najiang:]},
  publisher     = {ACM},
}

@Book{vonneumann2007theory,
  title         = {Theory of games and economic behavior (60th Anniversary Commemorative Edition)},
  publisher     = {Princeton university press},
  year          = {2007},
  author        = {Von Neumann, John and Morgenstern, Oskar},
  __markedentry = {[najiang:]},
}

@InProceedings{chajewska2000making,
  author        = {Chajewska, Urszula and Koller, Daphne and Parr, Ronald},
  title         = {Making rational decisions using adaptive utility elicitation},
  booktitle     = {AAAI/IAAI},
  year          = {2000},
  pages         = {363--369},
  __markedentry = {[najiang:]},
}

@InCollection{balcan2007margin,
  author        = {Balcan, Maria-Florina and Broder, Andrei and Zhang, Tong},
  title         = {Margin based active learning},
  booktitle     = {Learning Theory},
  publisher     = {Springer},
  year          = {2007},
  pages         = {35--50},
  __markedentry = {[najiang:]},
}

@Article{balcan2012active,
  author        = {Balcan, Maria Florina and Long, Philip M},
  title         = {Active and passive learning of linear separators under log-concave distributions},
  journal       = {arXiv preprint arXiv:1211.1082},
  year          = {2012},
  __markedentry = {[najiang:]},
}

@InProceedings{dasgupta2005coarse,
  author        = {Dasgupta, Sanjoy},
  title         = {Coarse sample complexity bounds for active learning},
  booktitle     = {Advances in Neural Information Processing Systems},
  year          = {2005},
  pages         = {235--242},
  __markedentry = {[najiang:]},
}

@InProceedings{regan2009regret,
  author        = {Regan, Kevin and Boutilier, Craig},
  title         = {Regret-based reward elicitation for Markov decision processes},
  booktitle     = {Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence},
  year          = {2009},
  pages         = {444--451},
  organization  = {AUAI Press},
  __markedentry = {[najiang:]},
}

@InCollection{lopes2009active,
  author        = {Lopes, Manuel and Melo, Francisco and Montesano, Luis},
  title         = {Active learning for reward estimation in inverse reinforcement learning},
  booktitle     = {Machine Learning and Knowledge Discovery in Databases},
  publisher     = {Springer},
  year          = {2009},
  pages         = {31--46},
  __markedentry = {[najiang:]},
}

@Article{baranes2013active,
  author        = {Baranes, Adrien and Oudeyer, Pierre-Yves},
  title         = {Active learning of inverse models with intrinsically motivated goal exploration in robots},
  journal       = {Robotics and Autonomous Systems},
  year          = {2013},
  volume        = {61},
  number        = {1},
  pages         = {49--73},
  __markedentry = {[najiang:]},
  publisher     = {Elsevier},
}

@InCollection{rothkopf2011preference,
  author        = {Rothkopf, Constantin A and Dimitrakakis, Christos},
  title         = {Preference elicitation and inverse reinforcement learning},
  booktitle     = {Machine Learning and Knowledge Discovery in Databases},
  publisher     = {Springer},
  year          = {2011},
  pages         = {34--48},
  __markedentry = {[najiang:]},
}

@InProceedings{langford2005relating,
  author        = {Langford, John and Zadrozny, Bianca},
  title         = {Relating reinforcement learning performance to classification performance},
  booktitle     = {Proceedings of the 22nd international conference on Machine learning},
  year          = {2005},
  pages         = {473--480},
  organization  = {ACM},
  __markedentry = {[najiang:]},
}

@InProceedings{lagoudakis2003reinforcement,
  author        = {Lagoudakis, Michail and Parr, Ronald},
  title         = {Reinforcement learning as classification: Leveraging modern classifiers},
  booktitle     = {ICML},
  year          = {2003},
  volume        = {3},
  pages         = {424--431},
  __markedentry = {[najiang:]},
}

@Book{boyd2004convex,
  title         = {Convex optimization},
  publisher     = {Cambridge university press},
  year          = {2004},
  author        = {Boyd, Stephen and Vandenberghe, Lieven},
  __markedentry = {[najiang:]},
}

@Article{elghaoui2002inversion,
  author        = {El Ghaoui, Laurent},
  title         = {Inversion error, condition number, and approximate inverses of uncertain matrices},
  journal       = {Linear algebra and its applications},
  year          = {2002},
  volume        = {343},
  pages         = {171--193},
  __markedentry = {[najiang:]},
  publisher     = {Elsevier},
}

@Book{anthony2009neural,
  title         = {Neural network learning: Theoretical foundations},
  publisher     = {cambridge university press},
  year          = {2009},
  author        = {Anthony, Martin and Bartlett, Peter L},
  __markedentry = {[najiang:]},
}

@Article{massart2006risk,
  author        = {Massart, Pascal and N{\'e}d{\'e}lec, {\'E}lodie},
  title         = {Risk bounds for statistical learning},
  journal       = {The Annals of Statistics},
  year          = {2006},
  pages         = {2326--2366},
  __markedentry = {[najiang:]},
  publisher     = {JSTOR},
}

@InProceedings{regan2011eliciting,
  author        = {Regan, Kevin and Boutilier, Craig},
  title         = {Eliciting additive reward functions for Markov decision processes},
  booktitle     = {IJCAI Proceedings-International Joint Conference on Artificial Intelligence},
  year          = {2011},
  volume        = {22},
  number        = {3},
  pages         = {2159},
  __markedentry = {[najiang:]},
}

@Article{kocsis2006improved,
  author        = {Kocsis, Levente and Szepesv{\'a}ri, Csaba and Willemson, Jan},
  title         = {Improved {M}onte-{C}arlo search},
  journal       = {Univ. Tartu, Estonia, Tech. Rep},
  year          = {2006},
  volume        = {1},
  __markedentry = {[najiang:6]},
}

@InProceedings{wang2007modifications,
  author        = {Wang, Yizao and Gelly, Sylvain},
  title         = {Modifications of {UCT} and sequence-like simulations for {M}onte-{C}arlo Go},
  booktitle     = {IEEE Symposium on Computational Intelligence and Games},
  year          = {2007},
  pages         = {175--182},
  __markedentry = {[najiang:6]},
}

@Article{silver2010monte,
  author        = {Silver, David and Veness, Joel},
  title         = {{M}onte-{C}arlo planning in large {POMDP}s},
  journal       = {Advances in Neural Information Processing Systems},
  year          = {2010},
  volume        = {23},
  pages         = {2164--2172},
  __markedentry = {[najiang:6]},
}

@InProceedings{coueetoux2011adding,
  author        = {Cou{\"e}toux, Adrien and Doghmen, Hassen and others},
  title         = {Adding Double Progressive Widening to Upper Confidence Trees to Cope with Uncertainty in Planning Problems},
  booktitle     = {9th European Workshop on Reinforcement Learning},
  year          = {2011},
  __markedentry = {[najiang:6]},
}

@InCollection{coueetoux2011continuous,
  author        = {Cou{\"e}toux, Adrien and Hoock, Jean-Baptiste and Sokolovska, Nataliya and Teytaud, Olivier and Bonnard, Nicolas},
  title         = {Continuous upper confidence trees},
  booktitle     = {Learning and Intelligent Optimization},
  publisher     = {Springer},
  year          = {2011},
  pages         = {433--445},
  __markedentry = {[najiang:6]},
}

@Article{tolpin2012mcts,
  author        = {Tolpin, David and Shimony, Solomon Eyal},
  title         = {{MCTS} based on simple regret},
  journal       = {AAAI. AAAI Press, 2012a. To appear},
  year          = {2012},
  __markedentry = {[najiang:6]},
}

@InProceedings{hingston2007experiments,
  author        = {Hingston, Philip and Masek, Martin},
  title         = {Experiments with {M}onte-{C}arlo {O}thello},
  booktitle     = {Evolutionary Computation},
  year          = {2007},
  pages         = {4059--4064},
  organization  = {IEEE},
  __markedentry = {[najiang:6]},
}

@Article{rasmussen2004gaussian,
  author        = {Rasmussen, Carl Edward and Kuss, Malte},
  title         = {Gaussian processes in reinforcement learning},
  journal       = {Advances in Neural Information Processing Systems},
  year          = {2004},
  volume        = {16},
  __markedentry = {[najiang:6]},
}

@Article{gelly2011monte,
  author        = {Gelly, Sylvain and Silver, David},
  title         = {{M}onte-{C}arlo tree search and rapid action value estimation in computer Go},
  journal       = {Artificial Intelligence},
  year          = {2011},
  volume        = {175},
  number        = {11},
  pages         = {1856--1875},
  __markedentry = {[najiang:6]},
  publisher     = {Elsevier},
}

@InProceedings{narayanamurthy2007efficiently,
  author        = {Narayanamurthy, Shravan Matthur and Ravindran, Balaraman},
  title         = {Efficiently Exploiting Symmetries in Real Time Dynamic Programming},
  booktitle     = {International Joint Conference on Artificial Intelligence},
  year          = {2007},
  pages         = {2556--2561},
  __markedentry = {[najiang:6]},
}

@Article{auer2002finite,
  author    = {Auer, Peter and Cesa-Bianchi, Nicol{\`o} and Fischer, Paul},
  title     = {Finite-time analysis of the multiarmed bandit problem},
  journal   = {Machine learning},
  year      = {2002},
  volume    = {47},
  number    = {2-3},
  pages     = {235--256},
  publisher = {Springer},
}

@Article{kearns2002sparse,
  author    = {Kearns, Michael and Mansour, Yishay and Ng, Andrew Y},
  title     = {A sparse sampling algorithm for near-optimal planning in large {M}arkov decision processes},
  journal   = {Machine Learning},
  year      = {2002},
  volume    = {49},
  number    = {2-3},
  pages     = {193--208},
  publisher = {Springer},
}

@InProceedings{konda2000actor,
  author    = {Konda, Vijay R and Tsitsiklis, John N},
  title     = {Actor-critic algorithms},
  booktitle = {Advances in neural information processing systems},
  year      = {2000},
  pages     = {1008--1014},
}

@Comment{jabref-meta: databaseType:bibtex;}

@article{azar2013minimax,
        title={Minimax PAC bounds on the sample complexity of reinforcement lear
ning with a generative model},
        author={Azar, Mohammad Gheshlaghi and Munos, R{\'e}mi and Kappen, Hilbert J},
        journal={Machine learning},
        volume={91},
        number={3},
        pages={325--349},
        year={2013},
        publisher={Springer}
}

@inproceedings{sidford2018vnear,
        title={Near-Optimal Time and Sample Complexities for for Solving Discounted Markov Decision Process with a Generative Model},
        author={Sidford, Aaron and Wang, Mengdi and Wu, Xian and Lin F. Yang and Ye, Yinyu},
        booktitle = {Advances in Neural Information Processing Systems 31},
        year={2018},
}

@article{bagnell2003covariant,
 author = {Bagnell, J. Andrew and Schneider, Jeff},
 title = {Covariant Policy Search},
 journal = {Proceedings of the 18th International Joint Conference on Artificial Intelligence},
 series = {IJCAI'03},
 year = {2003},
 pages = {1019--1024},
 numpages = {6},
 url = {http://dl.acm.org/citation.cfm?id=1630659.1630805},
 publisher = {Morgan Kaufmann Publishers Inc.},
 address = {San Francisco, CA, USA},
}


@InProceedings{Kakade01,
author =       "Kakade, S.",
title =        "A Natural Policy Gradient",
booktitle =    "NIPS",
year =         "2001",
}

@article{DBLP:journals/siamjo/GhadimiL13a,
  author    = {Saeed Ghadimi and
               Guanghui Lan},
  title     = {Stochastic First- and Zeroth-Order Methods for Nonconvex Stochastic
               Programming},
  journal   = {{SIAM} Journal on Optimization},
  volume    = {23},
  number    = {4},
  pages     = {2341--2368},
  year      = {2013},
}

@article{Bubeck:convex,
 author = {Bubeck, S{\'e}bastien},
 title = {Convex Optimization: Algorithms and Complexity},
 journal = {Found. Trends Mach. Learn.},
 volume = {8},
 year = {2015},
 issn = {1935-8237},
 pages = {231--357},
 numpages = {127},
 publisher = {Now Publishers Inc.},
}

@article{Jain:nonconvex,
 author = {Jain, Prateek and Kar, Purushottam},
 title = {Non-convex Optimization for Machine Learning},
 journal = {Found. Trends Mach. Learn.},
 volume = {10},
 year = {2017},
 issn = {1935-8237},
 pages = {142--336},
 numpages = {195},
 publisher = {Now Publishers Inc.},
}

@misc{agarwal2019optimality,
    title={On the Theory of Policy Gradient Methods: Optimality, Approximation, and Distribution Shift},
    author={Alekh Agarwal and Sham M. Kakade and Jason D. Lee and Gaurav Mahajan},
    year={2020},
    eprint={1908.00261},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@book{book:beck,
	author = {Beck, A.},
	title = {First-Order Methods in Optimization},
	publisher = {Society for Industrial and Applied Mathematics},
	year = {2017},
	doi = {10.1137/1.9781611974997},
	address = {Philadelphia, PA},
	edition   = {},
	eprint = {https://epubs.siam.org/doi/pdf/10.1137/1.9781611974997}
}


@article{DBLP:journals/mor/Ye11a,
  author    = {Yinyu Ye},
  title     = {The Simplex and Policy-Iteration Methods Are Strongly Polynomial for
               the Markov Decision Problem with a Fixed Discount Rate},
  journal   = {Math. Oper. Res.},
  volume    = {36},
  number    = {4},
  pages     = {593--603},
  year      = {2011},
}

@article{MS_PI,
author = {Mansour, Yishay and Singh, Satinder},
year = {1999},
month = {01},
title = {On the Complexity of Policy Iteration},
journal = {UAI}
}

@article{yinyu_CIPA,
author = {Ye, Yinyu},
year = {2005},
month = {08},
pages = {733-749},
title = {A New Complexity Result on Solving the Markov Decision Problem},
volume = {30},
journal = {Math. Oper. Res.},
}

@InCollection{McD89,
  author =       {C. McDiarmid},
  title =        {On the method of bounded differences},
  booktitle =    {Surveys in Combinatorics},
  pages =        {148--188},
  publisher =    {Cambridge University Press},
  year =         1989
}

@article{HsuSpectral,
author = {Hsu, Daniel and Kakade, Sham and Zhang, Tong},
year = {2008},
month = {11},
title = {A Spectral Algorithm for Learning Hidden Markov Models},
volume = {78},
journal = {Journal of Computer and System Sciences},
}

@InProceedings{pmlr-v125-agarwal20b,
  title = 	 {Model-Based Reinforcement Learning with a Generative Model is Minimax Optimal},
  author =       {Agarwal, Alekh and Kakade, Sham and Yang, Lin F.},
  pages = 	 {67--83},
  booktitle={COLT},
  year = 	 {2020},
  volume = 	 {125},
}

@inproceedings{kearns1999finite,
  title={Finite-sample convergence rates for Q-learning and indirect algorithms}
,
  author={Kearns, Michael J and Singh, Satinder P},
  booktitle={Advances in neural information processing systems},
  pages={996--1002},
  year={1999}
}

@article{li2020breaking,
  author    = {Gen Li and
               Yuting Wei and
               Yuejie Chi and
               Yuantao Gu and
               Yuxin Chen},
  title     = {Breaking the Sample Size Barrier in Model-Based Reinforcement Learning
               with a Generative Model},
  journal   = {CoRR},
  volume    = {abs/2005.12900},
  year      = {2020},
  archivePrefix = {arXiv},
  eprint    = {2005.12900},
}

@incollection{NIPS1999_1664,
title = {Approximate Planning in Large POMDPs via Reusable Trajectories},
author = {Michael J. Kearns and Mansour, Yishay and Andrew Y. Ng},
booktitle = {Advances in Neural Information Processing Systems 12},
editor = {S. A. Solla and T. K. Leen and K. M\"{u}ller},
pages = {1001--1007},
year = {2000},
publisher = {MIT Press},
}

@inproceedings{du2019good,
  title={Is a Good Representation Sufficient for Sample Efficient Reinforcement Learning?},
  author={Du, Simon S and Kakade, Sham M and Wang, Ruosong and Yang, Lin F},
  booktitle={International Conference on Learning Representations},
  year={2019}
}

@inproceedings{abelong,
    author = "Naoki Abe and Philip M. Long",
    title = "Associative reinforcement learning using linear probabilistic concepts",
    booktitle = "Proc. 16th International Conf. on Machine Learning",
    publisher = "Morgan Kaufmann, San Francisco, CA",
    pages = "3--11",
    year = "1999" 
}


@inproceedings{Rob52,
author= {H. Robbins},
  title = 	 {Some aspects of the sequential design of experiments},
  year = 	 {1952},
booktitle={Bulletin of the American Mathematical Society},
  volume = 	 {55}
}


@article{Auer02,
 author = {P. Auer and N. Cesa-Bianchi and P. Fischer},
 title = {Finite-time Analysis of the Multiarmed Bandit Problem},
 journal = {Mach. Learn.},
 volume = {47},
 number = {2-3},
 year = {2002},
 issn = {0885-6125},
 pages = {235--256},
 publisher = {Kluwer Academic Publishers},
 address = {Hingham, MA, USA},
 }

@inproceedings{bubeck2012towards,
  title={Towards minimax policies for online linear optimization with bandit feedback},
  author={Bubeck, S{\'e}bastien and Cesa-Bianchi, Nicolo and Kakade, Sham M},
  booktitle={COLT},
  year={2012}
}

@article{rusmevichientong2010linearly,
  title={Linearly parameterized bandits},
  author={Rusmevichientong, Paat and Tsitsiklis, John N},
  journal={Math of OR},
  year={2010},
}

@inproceedings{abbasi2011improved,
  title={Improved algorithms for linear stochastic bandits},
  author={Abbasi-Yadkori, Yasin and P{\'a}l, D{\'a}vid and Szepesv{\'a}ri, Csaba},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2312--2320},
  year={2011}
}

@book{puterman1994markov,
  title={Markov Decision Processes: Discrete Stochastic Dynamic Programming},
  author={Puterman, Martin},
  year={1994},
  publisher={Wiley-Interscience}
}

@InProceedings{pmlr-v70-azar17a,
  title = 	 {Minimax Regret Bounds for Reinforcement Learning},
  author =       {Mohammad Gheshlaghi Azar and Ian Osband and R{\'e}mi Munos},
  pages = 	 {263--272},
  year = 	 {2017},
  editor = 	 {Doina Precup and Yee Whye Teh},
  volume = 	 {70},
  booktitle = 	 {Proceedings of Machine Learning Research},
  address = 	 {International Convention Centre, Sydney, Australia},
  month = 	 {06--11 Aug},
  publisher =    {PMLR},
}

@inproceedings{kearns1999efficient,
  title={Efficient reinforcement learning in factored MDPs},
  author={Kearns, Michael and Koller, Daphne},
  booktitle={IJCAI},
  volume={16},
  pages={740--747},
  year={1999}
}

@inproceedings{sun2019model,
  title={Model-based rl in contextual decision processes: Pac bounds and exponential improvements over model-free approaches},
  author={Sun, Wen and Jiang, Nan and Krishnamurthy, Akshay and Agarwal, Alekh and Langford, John},
  booktitle={Conference on Learning Theory},
  pages={2898--2933},
  year={2019}
}


@article{brafman2002r,
  title={R-max-a general polynomial time algorithm for near-optimal reinforcement learning},
  author={Brafman, Ronen I and Tennenholtz, Moshe},
  journal={Journal of Machine Learning Research},
  volume={3},
  number={Oct},
  pages={213--231},
  year={2002}
}


@inproceedings{dann2017unifying,
  title={Unifying PAC and regret: Uniform PAC bounds for episodic reinforcement learning},
  author={Dann, Christoph and Lattimore, Tor and Brunskill, Emma},
  booktitle={Advances in Neural Information Processing Systems},
  pages={5713--5723},
  year={2017}
}

@article{glynn_likelihood,
author = {Glynn, Peter W.},
title = {Likelihood Ratio Gradient Estimation for Stochastic Systems},
year = {1990},
issue_date = {Oct. 1990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {33},
number = {10},
issn = {0001-0782},
journal = {Commun. ACM},
pages = {7584}
}

@misc{mei2020global,
      title={On the Global Convergence Rates of Softmax Policy Gradient Methods}, 
      author={Jincheng Mei and Chenjun Xiao and Csaba Szepesvari and Dale Schuurmans},
      year={2020},
      eprint={2005.06392},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}



@inproceedings{mnih2016asynchronous,
  title={Asynchronous methods for deep reinforcement learning},
  author={Mnih, Volodymyr and Badia, Adria Puigdomenech and Mirza, Mehdi and Graves, Alex and Lillicrap, Timothy and Harley, Tim and Silver, David and Kavukcuoglu, Koray},
  booktitle={International conference on machine learning},
  pages={1928--1937},
  year={2016}
}

@proceedings{ahmed2019understanding,
title	= {Understanding the impact of entropy on policy optimization},
editor	= {Zafarali Ahmed and Nicolas Le Roux and Mohammad Norouzi and Dale Schuurmans},
year	= {2019},
URL	= {https://arxiv.org/abs/1811.11214}
}

@article{Peters:2008:NA:1352927.1352986,
 author = {Peters, Jan and Schaal, Stefan},
 title = {Natural Actor-Critic},
 journal = {Neurocomput.},
 volume = {71},
 number = {7-9},
 year = {2008},
 issn = {0925-2312},
 pages = {1180--1190},
 numpages = {11},
 publisher = {Elsevier Science Publishers B. V.},
}


@inproceedings{scherrer2014approximate,
  title={Approximate policy iteration schemes: a comparison},
  author={Scherrer, Bruno},
  booktitle={International Conference on Machine Learning},
  pages={1314--1322},
  year={2014}
}

@inproceedings{scherrer2014local,
  title={Local policy search in a convex space and conservative policy iteration as boosted policy search},
  author={Scherrer, Bruno and Geist, Matthieu},
  booktitle={Joint European Conference on Machine Learning and Knowledge Discovery in Databases},
  pages={35--50},
  year={2014},
  organization={Springer}
}

@inproceedings{bagnell2004policy,
  title={Policy search by dynamic programming},
  author={Bagnell, J Andrew and Kakade, Sham M and Schneider, Jeff G and Ng, Andrew Y},
  booktitle={Advances in neural information processing systems},
  pages={831--838},
  year={2004}
}

@article{agarwal2020pc,
  title={Pc-pg: Policy cover directed exploration for provable policy gradient learning},
  author={Agarwal, Alekh and Henaff, Mikael and Kakade, Sham and Sun, Wen},
  journal={NeurIPS},
  year={2020}
}

@article{burda2018exploration,
  title={Exploration by random network distillation},
  author={Burda, Yuri and Edwards, Harrison and Storkey, Amos and Klimov, Oleg},
  journal={arXiv preprint arXiv:1810.12894},
  year={2018}
}

@book{lattimore2020bandit,
  title={Bandit algorithms},
  author={Lattimore, Tor and Szepesv{\'a}ri, Csaba},
  year={2020},
  publisher={Cambridge University Press}
}

@inproceedings{abbasi2019politex,
  title={{POLITEX}: Regret bounds for policy iteration using expert prediction},
  author={Abbasi-Yadkori, Yasin and Bartlett, Peter and Bhatia, Kush and Lazic, Nevena and Szepesvari, Csaba and Weisz, Gell{\'e}rt},
  booktitle={International Conference on Machine Learning},
  pages={3692--3702},
  year={2019}
}

@article{caiTRPO,
  author    = {Boyi Liu and
               Qi Cai and
               Zhuoran Yang and
               Zhaoran Wang},
  journal   = {CoRR},
  title     = {Neural Proximal/Trust Region Policy Optimization Attains Globally
               Optimal Policy},
  volume    = {abs/1906.10306},
  year      = {2019},
  url       = {http://arxiv.org/abs/1906.10306},
  archivePrefix = {arXiv},
  eprint    = {1906.10306},
}

@article{DBLP:journals/corr/NeuJG17,
  author    = {Gergely Neu and
               Anders Jonsson and
               Vicen{\c{c}} G{\'{o}}mez},
  title     = {A unified view of entropy-regularized Markov decision processes},
  journal   = {CoRR},
  volume    = {abs/1705.07798},
  year      = {2017}
}

@article{geist2019theory,
  title={A Theory of Regularized Markov Decision Processes},
  author={Geist, Matthieu and Scherrer, Bruno and Pietquin, Olivier},
  journal={arXiv preprint arXiv:1901.11275},
  year={2019}
}

@inproceedings{schulman2015trust,
  title={Trust region policy optimization},
  author={Schulman, John and Levine, Sergey and Abbeel, Pieter and Jordan, Michael and Moritz, Philipp},
  booktitle={International Conference on Machine Learning},
  pages={1889--1897},
  year={2015}
}


@inproceedings{jin2020provably,
  title={Provably efficient reinforcement learning with linear function approximation},
  author={Jin, Chi and Yang, Zhuoran and Wang, Zhaoran and Jordan, Michael I},
  booktitle={Conference on Learning Theory},
  pages={2137--2143},
  year={2020}
}

@article{lykouris2019corruption,
  title={Corruption robust exploration in episodic reinforcement learning},
  author={Lykouris, Thodoris and Simchowitz, Max and Slivkins, Aleksandrs and Sun, Wen},
  journal={arXiv preprint arXiv:1911.08689},
  year={2019}
}

@inproceedings{munos2005error,
  title={Error bounds for approximate value iteration},
  author={Munos, R{\'e}mi},
  year={2005},
  booktitle={AAAI}
}

@article{lazaric2016analysis,
  title={Analysis of classification-based policy iteration algorithms},
  author={Lazaric, Alessandro and Ghavamzadeh, Mohammad and Munos, R{\'e}mi},
  journal={The Journal of Machine Learning Research},
  volume={17},
  number={1},
  pages={583--612},
  year={2016},
  publisher={JMLR. org}
}

@inproceedings{chen2019information,
  title={Information-Theoretic Considerations in Batch Reinforcement Learning},
  author={Chen, Jinglin and Jiang, Nan},
  booktitle={International Conference on Machine Learning},
  pages={1042--1051},
  year={2019}
}

@article{zhou2020provably,
  title={Provably Efficient Reinforcement Learning for Discounted MDPs with Feature Mapping},
  author={Zhou, Dongruo and He, Jiafan and Gu, Quanquan},
  journal={arXiv preprint arXiv:2006.13165},
  year={2020}
}

@article{ayoub2020,
  author    = {Alex Ayoub and
               Zeyu Jia and
               Csaba Szepesv{\'{a}}ri and
               Mengdi Wang and
               Lin F. Yang},
  title     = {Model-Based Reinforcement Learning with Value-Targeted Regression},
  journal={arXiv preprint arXiv:2006.01107},
  year      = {2020},
  url       = {https://arxiv.org/abs/2006.01107},
}

@article{yang2019reinforcement,
  title={Reinforcement leaning in feature space: Matrix bandit, kernels, and regret bound},
  author={Yang, Lin F and Wang, Mengdi},
  journal={arXiv preprint arXiv:1905.10389},
  year={2019}
}

@inproceedings{yang2019sample,
  title={Sample-Optimal Parametric Q-Learning Using Linearly Additive Features},
  author={Yang, Lin F. and Wang, Mengdi},
  booktitle={International Conference on Machine Learning},
  pages={6995--7004},
  year={2019}
}

@article{pmlr-v120-jia20a,
title = {Model-Based Reinforcement Learning with Value-Targeted Regression},
author = {Jia, Zeyu and Yang, Lin and Szepesvari, Csaba and Wang, Mengdi},
pages = {666--686}, year = {2020},
volume = {120},
journal = {Proceedings of Machine Learning Research}, 
publisher = {PMLR},
}

@article{osband2016on,
        title={On Lower Bounds for Regret in Reinforcement Learning},
        author={Ian Osband and Van Roy, Benjamin},
        journal={ArXiv},
        year={2016},
        volume={abs/1608.02732}
}

@article{Schulman2017ProximalPO,
  title={Proximal Policy Optimization Algorithms},
  author={John Schulman and F. Wolski and Prafulla Dhariwal and A. Radford and O. Klimov},
  journal={ArXiv},
  year={2017},
  volume={abs/1707.06347}
}


@inproceedings{DBLP:conf/aistats/0002JTS20,
  author    = {Aditya Modi and
               Nan Jiang and
               Ambuj Tewari and
               Satinder P. Singh},
  title     = {Sample Complexity of Reinforcement Learning using Linearly Combined
               Model Ensembles},
  booktitle = {The 23rd International Conference on Artificial Intelligence and Statistics,
               {AISTATS}},
  series    = {Proceedings of Machine Learning Research},
  volume    = {108},
  year      = {2020},
}

@article{SDP-LQR,
 author= {Balakrishnan, V. and Vandenberghe, L.},
title={Semidefinite programming duality and linear time-invariant systems},
journal= {IEEE Transactions on Automatic Control},
number = {1},
volume = {48},
pages = {30--41},
year = {2003}
}

@book{Anderson:1990:OCL:79089,
 author = {Anderson, Brian D. O. and Moore, John B.},
 title = {Optimal Control: Linear Quadratic Methods},
 year = {1990},
 isbn = {0-13-638560-5},
 publisher = {Prentice-Hall, Inc.},
 address = {Upper Saddle River, NJ, USA},
} 

@article{Evans2005,
author = {Evans, Lawrence C.},
isbn = {1471-2334},
issn = {14712334},
journal = {University of California, Department of Mathematics},
pages = {126},
pmid = {20170501},
title = {{An introduction to mathematical optimal control theory}},
year = {2005}
}

@inproceedings{cohen2019learning,
  title={Learning Linear-Quadratic Regulators Efficiently with only sqrt{{T
}} Regret},
  author={Cohen, Alon and Koren, Tomer and Mansour, Yishay},
  booktitle={International Conference on Machine Learning},
  pages={1300--1309},
  year={2019}
}

@inproceedings{ICML-2018-Fazel0KM,
	author        = "Maryam Fazel and Rong Ge 0001 and Sham M. Kakade and Mehran Mesbahi",
	booktitle     = "{Proceedings of the 35th International Conference on Machine Learning}",
	ee            = "http://proceedings.mlr.press/v80/fazel18a.html",
	pages         = "1466--1475",
	publisher     = "{PMLR}",
	title         = "{Global Convergence of Policy Gradient Methods for the Linear Quadratic Regulator}",
	year          = 2018,
}

@Book{Bertsekas:DP,
author= {Bertsekas, Dimitri P.},
title= {Dynamic Programming and Optimal Control},
publisher={Athena Scientific},
year={2017}
}

@inproceedings{pomerleau1989alvinn,
  title={Alvinn: An autonomous land vehicle in a neural network},
  author={Pomerleau, Dean A},
  booktitle={Advances in neural information processing systems},
  pages={305--313},
  year={1989}
}

@inproceedings{ross2010efficient,
  title={Efficient reductions for imitation learning},
  author={Ross, St{\'e}phane and Bagnell, Drew},
  booktitle={Proceedings of the thirteenth international conference on artificial intelligence and statistics},
  pages={661--668},
  year={2010}
}


@inproceedings{kitani2012activity,
  title={Activity forecasting},
  author={Kitani, Kris M and Ziebart, Brian D and Bagnell, James Andrew and Hebert, Martial},
  booktitle={European Conference on Computer Vision},
  pages={201--214},
  year={2012},
  organization={Springer}
}
@inproceedings{ziebart2009planning,
  title={Planning-based prediction for pedestrians},
  author={Ziebart, Brian D and Ratliff, Nathan and Gallagher, Garratt and Mertz, Christoph and Peterson, Kevin and Bagnell, J Andrew and Hebert, Martial and Dey, Anind K and Srinivasa, Siddhartha},
  booktitle={2009 IEEE/RSJ International Conference on Intelligent Robots and Systems},
  pages={3931--3936},
  year={2009},
  organization={IEEE}
}

@inproceedings{ho2016generative,
  title={Generative adversarial imitation learning},
  author={Ho, Jonathan and Ermon, Stefano},
  booktitle={Advances in neural information processing systems},
  pages={4565--4573},
  year={2016}
}

@article{ke2019imitation,
  title={Imitation Learning as $ f $-Divergence Minimization},
  author={Ke, Liyiming and Barnes, Matt and Sun, Wen and Lee, Gilwoo and Choudhury, Sanjiban and Srinivasa, Siddhartha},
  journal={arXiv preprint arXiv:1905.12888},
  year={2019}
}

@article{sun2019provably,
  title={Provably efficient imitation learning from observation alone},
  author={Sun, Wen and Vemula, Anirudh and Boots, Byron and Bagnell, J Andrew},
  journal={arXiv preprint arXiv:1905.10948},
  year={2019}
}

@inproceedings{brantley2019disagreement,
  title={Disagreement-regularized imitation learning},
  author={Brantley, Kiant{\'e} and Sun, Wen and Henaff, Mikael},
  booktitle={International Conference on Learning Representations},
  year={2019}
}
@article{hester2017deep,
  title={Deep q-learning from demonstrations},
  author={Hester, Todd and Vecerik, Matej and Pietquin, Olivier and Lanctot, Marc and Schaul, Tom and Piot, Bilal and Horgan, Dan and Quan, John and Sendonaris, Andrew and Dulac-Arnold, Gabriel and others},
  journal={arXiv preprint arXiv:1704.03732},
  year={2017}
}

@article{rajeswaran2017learning,
  title={Learning complex dexterous manipulation with deep reinforcement learning and demonstrations},
  author={Rajeswaran, Aravind and Kumar, Vikash and Gupta, Abhishek and Vezzani, Giulia and Schulman, John and Todorov, Emanuel and Levine, Sergey},
  journal={arXiv preprint arXiv:1709.10087},
  year={2017}
}

@article{cheng2018fast,
  title={Fast policy learning through imitation and reinforcement},
  author={Cheng, Ching-An and Yan, Xinyan and Wagener, Nolan and Boots, Byron},
  journal={arXiv preprint arXiv:1805.10413},
  year={2018}
}

@article{sun2018truncated,
  title={Truncated horizon policy search: Combining reinforcement learning \& imitation learning},
  author={Sun, Wen and Bagnell, J Andrew and Boots, Byron},
  journal={arXiv preprint arXiv:1805.11240},
  year={2018}
}

@article{sun2017deeply,
  title={Deeply aggrevated: Differentiable imitation learning for sequential prediction},
  author={Sun, Wen and Venkatraman, Arun and Gordon, Geoffrey J and Boots, Byron and Bagnell, J Andrew},
  journal={arXiv preprint arXiv:1703.01030},
  year={2017}
}

@article{ross2014reinforcement,
  title={Reinforcement and imitation learning via interactive no-regret learning},
  author={Ross, Stephane and Bagnell, J Andrew},
  journal={arXiv preprint arXiv:1406.5979},
  year={2014}
}

@inproceedings{chang2015learning,
  title={Learning to search better than your teacher},
  author={Chang, Kai-Wei and Krishnamurthy, Akshay and Agarwal, Alekh and Daume, Hal and Langford, John},
  booktitle={International Conference on Machine Learning},
  pages={2058--2066},
  year={2015},
  organization={PMLR}
}

@article{cheng2020policy,
  title={Policy Improvement from Multiple Experts},
  author={Cheng, Ching-An and Kolobov, Andrey and Agarwal, Alekh},
  journal={arXiv preprint arXiv:2007.00795},
  year={2020}
}

@article{cheng2018convergence,
  title={Convergence of value aggregation for imitation learning},
  author={Cheng, Ching-An and Boots, Byron},
  journal={arXiv preprint arXiv:1801.07292},
  year={2018}
}

@article{le2018hierarchical,
  title={Hierarchical imitation and reinforcement learning},
  author={Le, Hoang M and Jiang, Nan and Agarwal, Alekh and Dud{\'\i}k, Miroslav and Yue, Yisong and Daum{\'e} III, Hal},
  journal={arXiv preprint arXiv:1803.00590},
  year={2018}
}

@article{choudhury2018data,
  title={Data-driven planning via imitation learning},
  author={Choudhury, Sanjiban and Bhardwaj, Mohak and Arora, Sankalp and Kapoor, Ashish and Ranade, Gireeja and Scherer, Sebastian and Dey, Debadeepta},
  journal={The International Journal of Robotics Research},
  volume={37},
  number={13-14},
  pages={1632--1672},
  year={2018},
  publisher={SAGE Publications Sage UK: London, England}
}

@article{daume2009search,
  title={Search-based structured prediction},
  author={Daum{\'e}, Hal and Langford, John and Marcu, Daniel},
  journal={Machine learning},
  volume={75},
  number={3},
  pages={297--325},
  year={2009},
  publisher={Springer}
}

@article{williams2017model,
	title={Model predictive path integral control: From theory to parallel computation},
	author={Williams, Grady and Aldrich, Andrew and Theodorou, Evangelos A.},
	journal={Journal of Guidance, Control, and Dynamics},
	volume={40},
	number={2},
	pages={344--357},
	year={2017},
	publisher={American Institute of Aeronautics and Astronautics}
}

@article{tedrake2009lqr,
  title={{LQR}-Trees: Feedback motion planning on sparse randomized trees},
  author={Tedrake, Russ},
  journal = {The International Journal of Robotics Research},
 volume = {35},
  year={2009},
  publisher={MIT Press}
}

@inproceedings{perez2012lqr,
  title={{LQR-RRT*}: Optimal sampling-based motion planning with automatically derived extension heuristics},
  author={Perez, Alejandro and Platt, Robert and Konidaris, George and Kaelbling, Leslie and Lozano-Perez, Tomas},
  booktitle={IEEE International Conference on Robotics and Automation},
  pages={2537--2542},
  year={2012},
}

@article{ahn2007iterative,
  title={Iterative learning control: Brief survey and categorization},
  author={Ahn, Hyo-Sung and Chen, YangQuan and Moore, Kevin L.},
  journal={IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)},
  volume={37},
  number={6},
  pages={1099--1121},
  year={2007},
}

@article{dean:2017,
archivePrefix = {arXiv},
arxivId = {arXiv:1710.01688},
author = {Dean, S. and Mania, H. and Matni, N. and Recht, B. and Tu, S.},
title = {On the Sample Complexity of the Linear Quadratic Regulator},
journal = {ArXiv e-prints},
year = {2017}
}

@article{mania2019certainty,
  title={Certainty equivalent control of {LQR} is efficient},
  author={Mania, Horia and Tu, Stephen and Recht, Benjamin},
  journal={arXiv preprint arXiv:1902.07826},
  year={2019}
}

@inproceedings{simchowitz2018learning,
  title={Learning Without Mixing: Towards A Sharp Analysis of Linear System
 Identification},
  author={Simchowitz, Max and Mania, Horia and Tu, Stephen and Jordan, Michael I and Recht, Benjamin},
  booktitle={COLT},
  year={2018}
}

@article{simchowitz2020naive,
  title={Naive exploration is optimal for online {LQR}},
  author={Simchowitz, Max and Foster, Dylan J},
  journal={arXiv preprint arXiv:2001.09576},
  year={2020}
}

@inproceedings{dean2018regret,
  title={Regret bounds for robust adaptive control of the linear quadratic regulator},
  author={Dean, Sarah and Mania, Horia and Matni, Nikolai and Recht, Benjamin and Tu, Stephen},
  booktitle={Advances in Neural Information Processing Systems},
  pages={4188--4197},
  year={2018}
}

@inproceedings{abbasi2011regret,
  title={Regret bounds for the adaptive control of linear quadratic systems},
  author={Abbasi-Yadkori, Yasin and Szepesv{\'a}ri, Csaba},
  booktitle={Conference on Learning Theory},
  pages={1--26},
  year={2011}
}

@inproceedings{Todorov04,
	title={A generalized iterative {LQG} method for locally-optimal feedback control of constrained nonlinear stochastic systems},
	author={Emanuel Todorov and Weiwei Li},
	booktitle={American Control Conference},
	pages={300--306},
	year={2005}
}

@inproceedings{levine2013guided,
  title={Guided policy search},
  author={Levine, Sergey and Koltun, Vladlen},
  booktitle={International Conference on Machine Learning},
  pages={1--9},
  year={2013}
}
@inproceedings{levine2014learning,
  title={Learning neural network policies with guided policy search under unknown dynamics},
  author={Levine, Sergey and Abbeel, Pieter},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1071--1079},
  year={2014}
}

@article{levine2018reinforcement,
  title={Reinforcement learning and control as probabilistic inference: Tutorial and review},
  author={Levine, Sergey},
  journal={arXiv preprint arXiv:1805.00909},
  year={2018}
}

@inproceedings{ziebart2010modeling,
  title={Modeling interaction via the principle of maximum causal entropy},
  author={Ziebart, Brian D and Bagnell, J Andrew and Dey, Anind K},
  booktitle = {Proceedings of the 27th International Conference on Machine Learning (ICML-10)},
  year={2010},
  publisher={Carnegie Mellon University}
}


@article{shalev2011online,
  author        = {Shalev-Shwartz, Shai},
  title         = {Online learning and online convex optimization},
  journal       = {Foundations and Trends in Machine Learning},
  year          = {2011},
  volume        = {4},
  number        = {2},
  pages         = {107--194},
}

@inproceedings{ross2011reduction,
  title={A reduction of imitation learning and structured prediction to no-regret online learning},
  author={Ross, St{\'e}phane and Gordon, Geoffrey and Bagnell, Drew},
  booktitle={Proceedings of the fourteenth international conference on artificial intelligence and statistics},
  pages={627--635},
  year={2011}
}

@book{geer2000empirical,
  title={Empirical Processes in M-estimation},
  author={Geer, Sara A and van de Geer, Sara},
  volume={6},
  year={2000},
  publisher={Cambridge university press}
}

@article{agarwal2020flambe,
  title={Flambe: Structural complexity and representation learning of low rank mdps},
  author={Agarwal, Alekh and Kakade, Sham and Krishnamurthy, Akshay and Sun, Wen},
  journal={NeurIPS},
  year={2020}
}


@article{wang2019system,
  title={A system-level approach to controller synthesis},
  author={Wang, Yuh-Shyang and Matni, Nikolai and Doyle, John C},
  journal={IEEE Transactions on Automatic Control},
  volume={64},
  number={10},
  pages={4079--4093},
  year={2019},
  publisher={IEEE}
}

@article{agarwal2019online,
  title={Online control with adversarial disturbances},
  author={Agarwal, Naman and Bullins, Brian and Hazan, Elad and Kakade, Sham M and Singh, Karan},
  journal={arXiv preprint arXiv:1902.08721},
  year={2019}
}

@article{youla1976modern,
  title={Modern Wiener-Hopf design of optimal controllers--Part II: The multivariable case},
  author={Youla, Dante and Jabr, Hamid and Bongiorno, Jr},
  journal={IEEE Transactions on Automatic Control},
  volume={21},
  number={3},
  pages={319--338},
  year={1976},
  publisher={IEEE}
}

@article{simchowitz2020improper,
  title={Improper learning for non-stochastic control},
  author={Simchowitz, Max and Singh, Karan and Hazan, Elad},
  journal={arXiv preprint arXiv:2001.09254},
  year={2020}
}

@inproceedings{zinkevich2003online,
  title={Online convex programming and generalized infinitesimal gradient ascent},
  author={Zinkevich, Martin},
  booktitle={Proceedings of the 20th international conference on machine learning (icml-03)},
  pages={928--936},
  year={2003}
}

@article{foster2020logarithmic,
  title={Logarithmic regret for adversarial online control},
  author={Foster, Dylan J and Simchowitz, Max},
  journal={arXiv preprint arXiv:2003.00189},
  year={2020}
}

@article{goel2020power,
  title={The Power of Linear Controllers in LQR Control},
  author={Goel, Gautam and Hassibi, Babak},
  journal={arXiv preprint arXiv:2002.02574},
  year={2020}
}

@article{munos2008finite,
  title={Finite-time bounds for fitted value iteration},
  author={Munos, R{\'e}mi and Szepesv{\'a}ri, Csaba},
  journal={Journal of Machine Learning Research},
  volume={9},
  number={May},
  pages={815--857},
  year={2008}
}


@article{duan_offline,
  author    = {Yaqi Duan and
               Mengdi Wang},
  title     = {Minimax-Optimal Off-Policy Evaluation with Linear Function Approximation},
  journal   = {arXiv},
  volume    = {abs/2002.09516},
  year      = {2020},
  url       = {https://arxiv.org/abs/2002.09516},
  archivePrefix = {arXiv},
  eprint    = {2002.09516},
}

@misc{wang2020statistical,
      title={What are the Statistical Limits of Offline RL with Linear Function Approximation?}, 
      author={Ruosong Wang and Dean P. Foster and Sham M. Kakade},
      year={2020},
      eprint={2010.11895},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@inproceedings{tosatto2017boosted,
  title={Boosted fitted q-iteration},
  author={Tosatto, Samuele and Pirotta, Matteo and dEramo, Carlo and Restelli, Marcello},
  booktitle={International Conference on Machine Learning},
  pages={3434--3443},
  year={2017},
  organization={PMLR}
}

@article{xie2020q,
  title={{$Q^{\star}$} Approximation Schemes for Batch Reinforcement Learning: A Theoretical Comparison},
  author={Xie, Tengyang and Jiang, Nan},
  journal={arXiv preprint arXiv:2003.03924},
  year={2020}
}


@book{devroye2012combinatorial,
  title={Combinatorial methods in density estimation},
  author={Devroye, Luc and Lugosi, G{\'a}bor},
  year={2012},
  publisher={Springer Science \& Business Media}
}

@inproceedings{WeiszAS21,
  author    = {Gell{\'{e}}rt Weisz and
               Philip Amortila and
               Csaba Szepesv{\'{a}}ri},
  title     = {Exponential Lower Bounds for Planning in MDPs With Linearly-Realizable
               Optimal Action-Value Functions},
  booktitle = {Algorithmic Learning Theory, 16-19 March 2021, Virtual Conference,
               Worldwide},
  series    = {Proceedings of Machine Learning Research},
  volume    = {132},
  year      = {2021},
}

@article{Wang_linear_lower,
  author    = {Yuanhao Wang and
               Ruosong Wang and
               Sham M. Kakade},
  title     = {An Exponential Lower Bound for Linearly-Realizable MDPs with Constant
               Suboptimality Gap},
  journal   = {CoRR},
  volume    = {abs/2103.12690},
  year      = {2021},
  url       = {https://arxiv.org/abs/2103.12690},
  eprinttype = {arXiv},
}
@article{wen2017efficient,
  title={Efficient reinforcement learning in deterministic systems with value function generalization},
  author={Wen, Zheng and Van Roy, Benjamin},
  journal={Mathematics of Operations Research},
  volume={42},
  number={3},
  pages={762--782},
  year={2017},
  publisher={INFORMS}
}
@Article{Shan50,
  Title                    = {Programming a Computer Playing Chess},
  Author                   = {Claude E. Shannon},
  Journal                  = {Philosophical Magazine},
  Year                     = {1959},
  Number                   = {312},
  Volume                   = {Ser.7, 41}
}
@book{todd2016minimum,
  title={Minimum-Volume Ellipsoids: Theory and Algorithms},
  author={Todd, Michael J},
  volume={23},
  year={2016},
  publisher={SIAM}
}
@article{Yin2021NearOP,
  title={Near Optimal Provable Uniform Convergence in Off-Policy Evaluation for Reinforcement Learning},
  author={Ming Yin and Yu Bai and Yu-Xiang Wang},
  journal={ArXiv},
  year={2021},
  volume={abs/2007.03760}
}
@article{ball1997elementary,
  author = {Ball, Keith},
  journal = {Flavors of geometry},
  keywords = {convex geometry john},
  pages = {1--58},
  publisher = {Cambridge University Press Cambridge},
  title = {An elementary introduction to modern convex geometry},
  volume = 31,
  year = 1997
}
@inproceedings{zanette2021exponential,
  author    = {Andrea Zanette},
  title     = {Exponential Lower Bounds for Batch Reinforcement Learning: Batch {RL}
               can be Exponentially Harder than Online {RL}},
  booktitle = {Proceedings of the 38th International Conference on Machine Learning,
               {ICML} 2021, 18-24 July 2021, Virtual Event},
  series    = {Proceedings of Machine Learning Research},
  publisher = {{PMLR}},
  year      = {2021},
}

@inproceedings{bilinear,
  author    = {Simon S. Du and
               Sham M. Kakade and
               Jason D. Lee and
               Shachar Lovett and
               Gaurav Mahajan and
               Wen Sun and
               Ruosong Wang},
  title     = {Bilinear Classes: {A} Structural Framework for Provable Generalization
               in {RL}},
  booktitle = {Proceedings of the 38th International Conference on Machine Learning,
               {ICML} 2021, 18-24 July 2021, Virtual Event},
  series    = {Proceedings of Machine Learning Research},
  volume    = {139},
  publisher = {{PMLR}},
  year      = {2021},
}
@inproceedings{eluder,
 author = {Russo, Daniel and Van Roy, Benjamin},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {C. J. C. Burges and L. Bottou and M. Welling and Z. Ghahramani and K. Q. Weinberger},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Eluder Dimension and the Sample Complexity of Optimistic Exploration},
 url = {https://proceedings.neurips.cc/paper/2013/file/41bfd20a38bb1b0bec75acf0845530a7-Paper.pdf},
 volume = {26},
 year = {2013}
}
@article{wang2020reinforcement,
  title={Reinforcement learning with general value function approximation: 
Provably efficient approach via bounded eluder dimension},
  author={Wang, Ruosong and Salakhutdinov, Russ R and Yang, Lin},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  year={2020}
}
@inproceedings{dong2020root,
  title={Root-n-Regret for Learning in Markov Decision Processes with Function Approximation and Low Bellman Rank},
  author={Dong, Kefan and Peng, Jian and Wang, Yining and Zhou, Yuan},
  booktitle={Conference on Learning Theory},
  pages={1554--1557},
  year={2020},
  organization={PMLR}
}
@misc{weisz2021tensorplan,
      title={TensorPlan and the Few Actions Lower Bound for Planning in MDPs under Linear Realizability of Optimal Value Functions}, 
      author={Gellrt Weisz and Csaba Szepesvri and Andrs Gyrgy},
      year={2021},
      eprint={2110.02195},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
